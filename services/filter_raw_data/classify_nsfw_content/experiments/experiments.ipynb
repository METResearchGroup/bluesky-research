{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classifying NSFW content\n",
    "\n",
    "We want a way to be able to classify if the Bluesky posts contain NSFW content. We vaguely know, I would think, if something has NSFW content if we see it, but I'd like to define it more precisely.\n",
    "\n",
    "According to [Merriam Webster](https://www.merriam-webster.com/dictionary/NSFW), NSFW means \"not safe for work; not suitable for work â€”used to warn someone that a website, email attachment, etc., is not suitable for viewing at most places of employment\". The [Wikipedia page](https://en.wikipedia.org/wiki/Not_safe_for_work) is slightly more descriptive, defining NSFW as:\n",
    "\n",
    "```plaintext\n",
    "Not safe for work (NSFW) is Internet slang or shorthand used to mark links to content, videos, or website pages the viewer may not wish to be seen viewing in a public, formal or controlled environment. The marked content may contain graphic violence, pornography, profanity, nudity, slurs or any other potentially disturbing subject matter. This may also include illegal activity such as piracy or inappropriate topic searches such as how to grow plant medicines, instructions for hacking or home-made explosives. Environments that may be problematic include workplaces, schools, and family settings. NSFW has particular relevance for people trying to make personal use of the Internet at workplaces or schools which have policies prohibiting access to sexual and graphic subject matter.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Our operational definition of NSFW content\n",
    "\n",
    "We'll keep our definition of NSFW content brief but specific. We're not trying to solve the problem of content moderation, we just need something that is good enough for our use case.\n",
    "\n",
    "Let's say that for our use case, NSFW content includes content such as:\n",
    "- Graphic violence\n",
    "- Pornography / sexual content and materials\n",
    "- Slurs\n",
    "\n",
    "In particular, we will most likely encounter sexual materials, so we want our NSFW classifier to be most robust to that type of content. Thus, we'll focus our work, as a first pass, on filtering out sexual content."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method 1: Using existing Bluesky content moderation features\n",
    "\n",
    "Bluesky already contains a few tools that will help us with our task, as part of their [moderation](https://docs.bsky.app/docs/advanced-guides/moderation) features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Labels\n",
    "\n",
    "Bluesky makes the use of labels which users or labelers can use to label posts. Some of the relevant labels for our use case include `porn`, `nudity`, and `sexual`; these are labels that have been added to posts (often by the post authors themselves) to flag content as having sexual content.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from services.filter_raw_data.classify_nsfw_content.constants import LABELS_TO_FILTER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['porn', 'furry', 'sexual', 'nudity', 'gore', 'graphic-media']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LABELS_TO_FILTER"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's grab a few posts and see what their labels are."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from services.sync.stream.database import FirehosePost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels: list[dict] = [\n",
    "    label.__data__ for label in FirehosePost.select(FirehosePost.labels)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "distinct_labels: list[str] = []\n",
    "for label in labels:\n",
    "    post_label = label[\"labels\"]\n",
    "    if post_label:\n",
    "        distinct_labels.append(post_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "distinct_labels: set[str] = set(distinct_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'nudity', 'porn', 'sexual'}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distinct_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can easily filter out posts if we look for cases where `post[\"label\"] in [\"nudity\", \"porn\", \"sexual\"]`. We define a list of inappropriate terms as constants, and we can just check if the labels are any of those."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method 2: AI-powered NSFW filter\n",
    "\n",
    "We could use some AI models to power NSFW filter. Before doing so, there are a few things to consider:\n",
    "\n",
    "- The community on Bluesky is more inclusive of niche interests and less spammy. Sexual content is unlikely to be from Onlyfans or from spam accounts, but instead from sex-positive users who want to build communities with other sex-positive users. Generally, I've observed that these groups enjoy the communities that they create but are understanding of the fact that other users may not want that content in their own feeds, so they provide labels for their content so others can filter them out accordingly.\n",
    "- User-powered labels should be able to account for most NSFW images.\n",
    "- Since Bluesky is much smaller than Twitter, the proliferation of NSFW content on Twitter doesn't really happen on Bluesky.\n",
    "- We can likely use a simple classifier or language model to detect if text has NSFW content (which should be better than a simple keyword-based approach, though it's likely that a keyword-based approach would get a lot of the way there)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Trying out ML filtering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Hugging Face models\n",
    "We can try something off-the-shelf to see how well it works. There's [this model](https://huggingface.co/michellejieli/NSFW_text_classifier) from Hugging Face, fine-tuned off 14,000 Reddit posts, that seems to work quite well. It appears to be the [most downloaded](https://huggingface.co/models?pipeline_tag=text-classification&sort=trending&search=nsfw) NSFW text classifier on Hugging Face. Looks like [this](https://www.linkedin.com/in/michellejieli/) is her LinkedIn profile, looks like she's a good engineer so I trust the model. I can use it for now, and as long as the NSFW classification makes sense I think we can just roll with it. Let me see how it does."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"michellejieli/NSFW_text_classifier\"\n",
    "classifier = pipeline(\"sentiment-analysis\", model=model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'NSFW', 'score': 0.9677894115447998}]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier(\"I see you've set aside this special time to humiliate yourself in public.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_is_nsfw_ml(text: str) -> bool:\n",
    "    \"\"\"Uses the classiifer to check if the text is NSFW or not.\"\"\"\n",
    "    result = classifier(text)\n",
    "    return result[0][\"label\"] == \"NSFW\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see how this does on a dataset. We don't have any tuned examples, and I'd rather not manually curate examples from Bluesky, so we'll use some training data as a proxy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's also see how the classifier does at scale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ml_tooling.inference_helpers import classify_posts, generate_batches_of_posts\n",
    "from services.sync.stream.helper import get_posts_as_list_dicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_posts = 50000\n",
    "posts: list[dict] = get_posts_as_list_dicts(k=num_posts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_post(post: dict) -> dict:\n",
    "    \"\"\"Do any preprocessing needed for the posts.\n",
    "\n",
    "    We only need the following fields:\n",
    "    - id\n",
    "    - uri\n",
    "    - text\n",
    "\n",
    "    We also want to remove any weird spacing or any newline characters.\n",
    "    \"\"\"\n",
    "    return {\n",
    "        \"id\": post[\"id\"],\n",
    "        \"uri\": post[\"uri\"],\n",
    "        # cleaning needed for language detection\n",
    "        \"text\": post[\"text\"].replace(\"\\n\", \" \").strip(),\n",
    "        # field needed for NSFW classification\n",
    "        \"labels\": post[\"labels\"]\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessed_posts: list[dict] = [preprocess_post(post) for post in posts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "batches: list[list[dict]] = generate_batches_of_posts(\n",
    "    posts=preprocessed_posts, batch_size=BATCH_SIZE\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clf_post_nsfw(post: dict) -> dict:\n",
    "    \"\"\"Classify the post as NSFW or not.\"\"\"\n",
    "    post_text = post[\"text\"]\n",
    "    post[\"is_nsfw\"] = text_is_nsfw_ml(post_text)\n",
    "    return post"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hf_nsfw_labels: list[dict] = classify_posts(\n",
    "#     posts=preprocessed_posts, clf_func=clf_post_nsfw,\n",
    "#     batch_size=BATCH_SIZE, rate_limit_per_minute=None\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This takes a long time to run (>8 minutes). Let's just QA a few results manually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 63378,\n",
       " 'uri': 'at://did:plc:m6cii5ipk35g32e4kz6lzklt/app.bsky.feed.post/3kpen5qta6z2p',\n",
       " 'text': 'é­šæ‹“  ãªã‚“ã§åœ°å‘³ã«ä¼¸ã³ãŸã‚“ã ',\n",
       " 'is_nsfw': True}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_post_nsfw(preprocessed_posts[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now classify a subset of the posts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset_preprocessed_posts = preprocessed_posts[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution time for classify_posts: 0 minutes, 3 seconds\n",
      "Memory usage for classify_posts: 104.4375 MB\n"
     ]
    }
   ],
   "source": [
    "hf_nsfw_labels: list[dict] = classify_posts(\n",
    "    posts=subset_preprocessed_posts, clf_func=clf_post_nsfw,\n",
    "    batch_size=BATCH_SIZE, rate_limit_per_minute=None\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at some of the classifications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_nsfw_posts = sum([1 for post in hf_nsfw_labels if post[\"is_nsfw\"]])\n",
    "nsfw_posts = [post for post in hf_nsfw_labels if post[\"is_nsfw\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "70"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_nsfw_posts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'id': 63378,\n",
       "  'uri': 'at://did:plc:m6cii5ipk35g32e4kz6lzklt/app.bsky.feed.post/3kpen5qta6z2p',\n",
       "  'text': 'é­šæ‹“  ãªã‚“ã§åœ°å‘³ã«ä¼¸ã³ãŸã‚“ã ',\n",
       "  'is_nsfw': True},\n",
       " {'id': 63380,\n",
       "  'uri': 'at://did:plc:5alnjqwjwsli7lgc4updk5a6/app.bsky.feed.post/3kpen5qzg722j',\n",
       "  'text': 'å¤šåˆ†ãŠã‚ŒãŒå¤©åº•ä¿¡è€…ã™ãŽã‚‹ã®ã‚‚ã‚ˆããªã„ å¤©åº•æŠœãé¸æŠžè‚¢ã¯æ™®é€šã«ã‚ã‚‹ã®ã«ã‚‚ã¯ã‚„å›ºå®šæž ã¿ãŸã„ãªæ‰±ã„ã—ã¦ã‚‹ çµ¶å¯¾é–“é•ã£ã¦ã‚‹',\n",
       "  'is_nsfw': True},\n",
       " {'id': 63381,\n",
       "  'uri': 'at://did:plc:7dgqrqv5w4jzaolkze2qgb4c/app.bsky.feed.post/3kpen5qvvbe2s',\n",
       "  'text': 'Los co-alcaldes municipales del Partido DEM entran en los Ayuntamientos ganados democrÃ¡ticamente acompaÃ±ados de cientos de personas y ponen fin al gobierno fiduciario.   anfespanol.com/elecciones-t...',\n",
       "  'is_nsfw': True}]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nsfw_posts[0:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like the classifier gets confused if the text is not English. Let's remove non-English posts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n"
     ]
    }
   ],
   "source": [
    "from services.filter_raw_data.classify_language.helper import classify_language_of_posts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like our English classifier works well based on our previous testing. Let's grab only the posts that are written in English."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution time for classify_posts: 0 minutes, 2 seconds\n",
      "Memory usage for classify_posts: 8.578125 MB\n"
     ]
    }
   ],
   "source": [
    "posts_with_language_labels: list[dict] = classify_language_of_posts(\n",
    "    posts=preprocessed_posts\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "posts_with_language_labels = [\n",
    "    {**post, **label}\n",
    "    for post, label in zip(preprocessed_posts, posts_with_language_labels)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 63376,\n",
       " 'uri': 'at://did:plc:sb6fu4sinwphqpvoznvz7efo/app.bsky.feed.post/3kpen5qxtnc2c',\n",
       " 'text': \"I'm having a lot of fun with this photo box\",\n",
       " 'is_english': True}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "posts_with_language_labels[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "english_posts = [post for post in posts_with_language_labels if post[\"is_english\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12028"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(english_posts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So ~12,000 of our 50,000 posts have been classified as English."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's grab a subset of the English posts and classify them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset_english_posts = english_posts[:100]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution time for classify_posts: 0 minutes, 3 seconds\n",
      "Memory usage for classify_posts: 83.21875 MB\n"
     ]
    }
   ],
   "source": [
    "hf_nsfw_labels: list[dict] = classify_posts(\n",
    "    posts=subset_english_posts, clf_func=clf_post_nsfw,\n",
    "    batch_size=BATCH_SIZE, rate_limit_per_minute=None\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, it took 3 seconds and 83MB to classify 100 posts. That's not very efficient. But, let's take a look at a few samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "nsfw_posts = [post for post in hf_nsfw_labels if post[\"is_nsfw\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "56"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(nsfw_posts) # 56/100 seems awfully high"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'id': 63390,\n",
       "  'uri': 'at://did:plc:6sfrfhw2vlakpteolhj75stl/app.bsky.feed.post/3kpen5tl3s42a',\n",
       "  'text': 'This sort of lines up with the top 10 consumption choices to radically reduce personal emissions, at least as far as mobility is concerned. ðŸ¤”  iopscience.iop.org/article/10.1...',\n",
       "  'is_english': True,\n",
       "  'is_nsfw': True},\n",
       " {'id': 63416,\n",
       "  'uri': 'at://did:plc:4rfp3cq3ycsfg6owkqrex5ls/app.bsky.feed.post/3kpen5x76kp2j',\n",
       "  'text': 'Agreed! ðŸ¤¢',\n",
       "  'is_english': True,\n",
       "  'is_nsfw': True},\n",
       " {'id': 63418,\n",
       "  'uri': 'at://did:plc:gyjeilekf6276652rhhvjs5c/app.bsky.feed.post/3kpen5xlwsl2l',\n",
       "  'text': '',\n",
       "  'is_english': True,\n",
       "  'is_nsfw': True},\n",
       " {'id': 63422,\n",
       "  'uri': 'at://did:plc:ev4c5s5yuffsikvdhcp4riri/app.bsky.feed.post/3kpen5ydus32n',\n",
       "  'text': \"protip: you won't make friends by following them around everywhere online and invading their personal space.  ass kissing does NOT help either. people pleasing and acting all clingy n shit is a huge turn off.   pls stop.\",\n",
       "  'is_english': True,\n",
       "  'is_nsfw': True},\n",
       " {'id': 63432,\n",
       "  'uri': 'at://did:plc:w5gpcazc2dp4ze2muqfej7ht/app.bsky.feed.post/3kpen5z7kgt2a',\n",
       "  'text': 'www.youtube.com/watch?v=Rtex...',\n",
       "  'is_english': True,\n",
       "  'is_nsfw': True}]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nsfw_posts[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OK, these just seem like nonsense results. Plus, classifying these seems to be very time and resource-heavy. It may be impractical to use ML unless we have other ways to speed up our inference. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Takeaways and next steps\n",
    "\n",
    "#### Current approach\n",
    "Currently, we can rely on a keyword and label-based approach. This should get us 80% of the way there in filtering NSFW content.\n",
    "- The communities that post NSFW content kindly provide labels to their content so that we can filter that content accordingly.\n",
    "- Otherwise, we can also just do simple filters on the text for particular keywords.\n",
    "\n",
    "Later, we can experiment with language models.\n",
    "\n",
    "Let's set up what these steps would look like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from services.sync.stream.helper import get_posts_as_list_dicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "posts = get_posts_as_list_dicts(k=50000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessed_posts = [preprocess_post(post) for post in posts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution time for classify_posts: 0 minutes, 2 seconds\n",
      "Memory usage for classify_posts: 0.078125 MB\n"
     ]
    }
   ],
   "source": [
    "posts_are_english_labels = classify_language_of_posts(preprocessed_posts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "posts_with_labels = [\n",
    "    {**post, **label}\n",
    "    for post, label in zip(preprocessed_posts, posts_are_english_labels)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "english_posts = [post for post in posts_with_labels if post[\"is_english\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12028\n",
      "{'id': 63376,\n",
      " 'is_english': True,\n",
      " 'labels': None,\n",
      " 'text': \"I'm having a lot of fun with this photo box\",\n",
      " 'uri': 'at://did:plc:sb6fu4sinwphqpvoznvz7efo/app.bsky.feed.post/3kpen5qxtnc2c'}\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "print(len(english_posts))\n",
    "pprint(english_posts[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_post_nsfw(post: dict) -> dict:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Things to consider including later on\n",
    "\n",
    "##### 1. Other features of Bluesky's moderation services.\n",
    "Bluesky uses [\"stackable moderation\"](https://bsky.social/about/blog/03-12-2024-stackable-moderation), which lets the user define what moderation looks like for their own feeds by subscribing to various lists and accounts that have their own rules for what posts to filter and remove. Bluesky has a tool called [Ozone](https://github.com/bluesky-social/ozone) which powers their crowdsourced content moderation. We can consider adopting some of those features, such as [lists](https://docs.bsky.app/docs/tutorials/user-lists), which would allow us to subscribe to lists of users (some communities, such as #furry, have kindly added their users to these lists so that their content can be easily filtered out), adding more example [labels](https://docs.bsky.app/docs/advanced-guides/moderation), or looking at other moderation tools that Bluesky has.\n",
    "\n",
    "Bluesky's moderation architecture is detailed more [here](https://docs.bsky.app/blog/blueskys-moderation-architecture).\n",
    "\n",
    "##### 2. Using a language model for NSFW classification\n",
    "A language model would likely do pretty well on NSFW classification, even in a zero-shot context. I'll have to build out more of the LLM infrastructure (and also just learn more about LLM engineering in the first place) in order to do it efficiently.\n",
    "\n",
    "\n",
    "##### 3. Using images for NSFW classification\n",
    "We could eventually use images as a feature for NSFW classification. Doing so requires that we:\n",
    "- Store the images (space constraints, plus we have to build the architecture for this since the firehose provides no way of obtaining this).\n",
    "- Efficiently classify the images (most images are OK).\n",
    "\n",
    "Since the communities on Bluesky that post NSFW content normally add labels accordingly and since there's not really much spam content (yet?) on Bluesky, we likely don't need to classify NSFW content ourselves.\n",
    "\n",
    "##### 4. How does our approach handle indirect speech (e.g., figures of speech, sarcasm)?\n",
    "How will our model (and more generally, our filtering steps) handle sarcasm, irony, and other figurative language?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bluesky-research",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
