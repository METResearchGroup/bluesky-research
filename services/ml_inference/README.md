# ML Inference

This service manages the inference components of the different ML models. Most of the actual inference code for each step is stored in `ml_tooling/`, and this service provides the scaffolding for running the inference components (e.g., loading data, managing parallelism, etc.).
