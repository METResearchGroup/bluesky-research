# Baseline Measures Analysis Across All Posts 2025-09-02

**Analysis Date**: September 2, 2025  
**Analysis Type**: Baseline Content Label Measures Across All Labeled Posts

## Purpose

This analysis calculates baseline measures (averages and proportions) for each content label across ALL labeled posts in the dataset, providing a comprehensive baseline without any user-specific filtering. This serves as a reference point for comparing user-specific analyses (feed content, engagement patterns) against the overall content landscape.

## What This Analysis Does

### **Core Functionality**
The analysis provides baseline measures by:

1. **Complete Coverage**: Analyzes ALL labeled posts in the dataset, not just those used in feeds or engaged with by study users
2. **Content Label Analysis**: Calculates averages and proportions for multiple ML classifiers:
   - **Perspective API**: Toxic vs. constructive content
   - **Sociopolitical**: Political ideology (left, moderate, right, unclear) and political vs. non-political
   - **IME (Intergroup, Moral, Emotion)**: Content categorization by social dynamics
   - **Valence Classifier**: Emotional tone (positive, negative, neutral)

3. **Time Aggregation**: Provides both daily and weekly aggregated baseline metrics
4. **Memory Efficiency**: Processes data day-by-day to handle large datasets without memory issues

### **Data Flow**

```text
All Labeled Posts → Day-by-Day Processing → Calculate Baseline Metrics → 
Daily/Weekly Aggregation → CSV Export
```

## Key Differences from Other Analyses

This analysis differs from other analytics scripts in important ways:

- **User Feed Analysis**: Analyzes only posts that appeared in users' feeds
- **User Engagement Analysis**: Analyzes only posts that users engaged with
- **Baseline Analysis**: Analyzes ALL labeled posts regardless of user interaction

This provides the complete picture of content characteristics across the entire dataset.

## Output Files

### **Data Files**

The analysis generates timestamped CSV files in the `results/` directory:

- **Daily Results**: `daily_baseline_content_label_metrics_{timestamp}.csv`
- **Weekly Results**: `weekly_baseline_content_label_metrics_{timestamp}.csv`
- **Total Average Results**: `total_average_baseline_content_label_metrics_{timestamp}.csv` (generated by summarization script)
- **Prevalence Analysis**: `label_prevalence_analysis_{timestamp}.csv` (generated by prevalence analysis script)
- **Prevalence Analysis (Markdown)**: `label_prevalence_analysis_{timestamp}.md` (human-readable format)

### **File Structure**

Each CSV contains:
- **Date/Week columns**: Temporal identifiers
- **Baseline user identifier**: "baseline" (not tied to specific users)
- **Content label metrics**: Averages and proportions for each ML classifier
- **Sample sizes**: Number of posts contributing to each metric

## Key Metrics Generated

### **Per-Day Baseline Metrics:**
- Average toxicity scores across all labeled posts
- Proportion of constructive content in the dataset
- Political orientation distributions
- Emotional valence patterns
- IME categorization distributions

### **Per-Week Baseline Metrics:**
- Weekly aggregated versions of all daily metrics
- Smoothed trends over time
- Baseline reference points for comparison with user-specific analyses

## Expected Insights

This analysis provides:

1. **Dataset Overview**: Complete picture of content characteristics across all labeled posts
2. **Baseline Reference**: Reference point for comparing user-specific content patterns
3. **Temporal Trends**: How overall content characteristics change over time
4. **Quality Assessment**: Understanding of the overall content landscape
5. **Comparison Context**: Baseline for evaluating whether user feeds/engagement differ from overall content

## File Structure

```text
get_baseline_measures_across_all_posts_2025_09_02/
├── main.py                              # Main analysis script
├── summarize_results_across_study.py    # Summarization script for total averages
├── analyze_prevalence.py                # Prevalence analysis script for label percentages
├── visualize_results.py                 # Visualization script for time series plots
├── submit_baseline_measures_analysis.sh # Slurm script for cluster execution
├── README.md                            # This documentation
└── results/                             # Output directory
    ├── daily_baseline_content_label_metrics_{timestamp}.csv
    ├── weekly_baseline_content_label_metrics_{timestamp}.csv
    ├── total_average_baseline_content_label_metrics_{timestamp}.csv
    ├── label_prevalence_analysis_{timestamp}.csv
    └── visualizations/                  # Visualization output directory
        └── {timestamp}/                 # Timestamped visualization run
            ├── daily/                   # Daily time series plots
            │   ├── average/             # Average metrics plots
            │   │   ├── toxic/           # Toxicity plots
            │   │   ├── constructive/    # Constructiveness plots
            │   │   └── ...              # Other traits
            │   └── proportion/          # Proportion metrics plots
            │       ├── is_sociopolitical/
            │       ├── is_valence_positive/
            │       └── ...
            └── weekly/                  # Weekly time series plots
                ├── average/             # Average metrics plots
                └── proportion/          # Proportion metrics plots
```

## Dependencies

- pandas
- Standard project libraries (lib.helper, lib.log, services.calculate_analytics.shared.*)

## Running the Analysis

### **Using Slurm Script (Recommended)**

The analysis should be run using the provided Slurm script on the cluster:

```bash
cd services/calculate_analytics/analyses/get_baseline_measures_across_all_posts_2025_09_02
sbatch submit_baseline_measures_analysis.sh
```

### **Manual Execution (Alternative)**

If running locally without Slurm:

```bash
cd services/calculate_analytics/analyses/get_baseline_measures_across_all_posts_2025_09_02
python main.py
```

### **Running the Summarization Script**

After the main analysis has completed and generated daily baseline results, you can run the summarization script to calculate total averages across all study days:

```bash
cd services/calculate_analytics/analyses/get_baseline_measures_across_all_posts_2025_09_02
python summarize_results_across_study.py
```

This script will:
- Automatically find the most recent daily baseline results CSV file
- Calculate the average of each baseline metric across all study days
- Export a single CSV file with total average baseline metrics
- Provide summary statistics about the analysis

### **Running the Prevalence Analysis Script**

After the summarization script has completed, you can run the prevalence analysis to get human-readable percentages for each content label:

```bash
cd services/calculate_analytics/analyses/get_baseline_measures_across_all_posts_2025_09_02
python analyze_prevalence.py
```

This script will:
- Automatically find the most recent total average baseline results CSV file
- Extract prevalence (proportion) metrics for each content label (NOT average probability scores)
- Display categorized results in the terminal
- Export both CSV and Markdown files with the analysis
- Provide organized, human-readable output by content category

**Important**: This script analyzes only "proportion" columns, which represent the percentage of posts that were actually classified as having each characteristic. It excludes "average" columns, which contain average probability scores and do not represent true prevalence.

## Visualization

### **Creating Time Series Plots**

After running the main analysis, you can generate time series visualizations using the `visualize_results.py` script:

```bash
cd services/calculate_analytics/analyses/get_baseline_measures_across_all_posts_2025_09_02
python visualize_results.py
```

### **Visualization Features**

The visualization script automatically:

1. **Finds Latest Results**: Locates the most recent analysis output files
2. **Creates Organized Structure**: Generates plots in the organized folder structure:

   ```text
   results/visualizations/<timestamp>/<daily/weekly>/<average/proportion>/<trait>.png
   ```
3. **Generates Time Series**: Creates publication-ready time series plots for each metric
4. **Includes Error Bars**: Shows standard deviation when available
5. **Proper Formatting**: Applies consistent styling and formatting

### **Visualization Output**

The script generates:
- **Daily Time Series**: Shows how baseline metrics change day-by-day
- **Weekly Time Series**: Shows weekly aggregated trends
- **Separate Plots**: One plot per metric type (average vs proportion) and trait
- **Organized Structure**: Easy to navigate folder organization by time period and metric type

### **Example Output Files**

```text
results/visualizations/2025-09-02-10-30-45/
├── daily/
│   ├── average/
│   │   ├── toxic/daily_toxic_baseline.png
│   │   ├── constructive/daily_constructive_baseline.png
│   │   └── ...
│   └── proportion/
│       ├── is_sociopolitical/daily_is_sociopolitical_baseline.png
│       ├── is_valence_positive/daily_is_valence_positive_baseline.png
│       └── ...
└── weekly/
    ├── average/
    │   ├── toxic/weekly_toxic_baseline.png
    │   └── ...
    └── proportion/
        ├── is_sociopolitical/weekly_is_sociopolitical_baseline.png
        └── ...
```

## Technical Details

### **Memory Management**
The script processes data day-by-day to manage memory usage:
- Loads labels for one partition date at a time
- Calculates baseline metrics for that day's data
- Cleans up memory before processing the next day
- Continues processing even if individual days fail

### **Error Handling**
- Comprehensive error handling with detailed logging
- Continues processing even if individual days fail
- Graceful handling of days with no labeled posts
- Detailed error messages for debugging

### **Data Processing**
- Uses `get_all_labels_for_posts(post_uris=None, load_all_labels=True)` to get ALL labeled posts
- Leverages shared analysis functions from the analytics framework
- Transforms results using existing transformation functions for consistency

## Usage in Downstream Analysis

The baseline measures generated by this analysis can be used to:

1. **Compare User Patterns**: Compare individual user feed/engagement patterns against baseline
2. **Identify Anomalies**: Find users whose content patterns significantly differ from baseline
3. **Temporal Analysis**: Track how user patterns change relative to baseline over time
4. **Condition Comparison**: Compare different experimental conditions against baseline
5. **Quality Assessment**: Evaluate whether user experiences differ from overall content landscape

## Integration with Other Analyses

This analysis complements other analytics scripts:

- **User Feed Analysis**: Compare feed content against baseline
- **User Engagement Analysis**: Compare engagement patterns against baseline  
- **Network Analysis**: Compare in-network vs out-of-network against baseline
- **Correlation Analysis**: Use baseline as reference point for correlation studies

## Notes

- The analysis processes ALL labeled posts, which may be a very large dataset
- Memory management is critical for successful execution
- Results provide the most comprehensive baseline available for comparison
- The "baseline" user identifier is used for consistency with existing transformation functions
