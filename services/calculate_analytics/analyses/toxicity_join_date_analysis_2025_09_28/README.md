# Toxicity vs Join Date Analysis Pipeline

This directory contains the analysis pipeline for investigating the relationship between user join dates on Bluesky and the toxicity/outrage levels of their posts. The analysis uses Perspective API labels to measure toxicity and moral outrage probabilities, then correlates these with user join dates to understand how platform behavior evolves over time.

## Analysis Goal

The primary research question is: **Do users who joined Bluesky at different times exhibit different levels of toxicity and moral outrage in their posts?**

This analysis will help understand:
- Whether early adopters vs. later joiners have different communication patterns
- How platform culture may have evolved over time
- Potential correlations between join timing and content moderation needs

## Pipeline Overview

The analysis follows a six-stage pipeline:

1. **Daily Processing**: Calculate author-to-average toxicity/outrage scores for each study day
2. **Aggregation**: Combine daily results into weighted averages across the entire study period
3. **Visualization**: Analyze and visualize posting patterns to understand data distribution
4. **Sampling**: Extract a representative sample of top users for detailed analysis
5. **Profile Fetching**: Retrieve Bluesky profile data including join dates for correlation analysis
6. **Join Date Analysis**: Visualize toxicity/outrage patterns by user join date

## Files and Execution Order

### 1. `get_author_to_average_toxicity_outrage.py`
**Purpose**: Processes daily Perspective API labeled posts to calculate author-level toxicity and outrage averages for each partition date.

**What it does**:
- Loads Perspective API labels and preprocessed posts for each study day
- Joins the data to match posts with their toxicity/outrage scores
- Calculates weighted averages of `prob_toxic` and `prob_moral_outrage` per author per day
- Exports daily results to parquet files in the cache directory

**Key outputs**:
- Daily parquet files with columns: `author_did`, `preprocessing_timestamp`, `average_toxicity`, `average_outrage`, `total_labeled_posts`
- Each file represents one partition date's worth of author-level aggregations

**Execution**: Run first to generate daily data
```bash
python get_author_to_average_toxicity_outrage.py
```

### 2. `aggregate_author_to_average_toxicity_across_days.py`
**Purpose**: Aggregates the daily author-to-average toxicity/outrage data into comprehensive weighted averages across the entire study period.

**What it does**:
- Loads all daily parquet files generated by the first script
- Calculates weighted averages across all days for each author using the formula:
  ```
  weighted_avg = sum(posts_per_day * avg_per_day) / sum(posts_per_day)
  ```
- Sorts results by total posts (descending) to identify most active authors
- Exports final aggregated results to timestamped parquet files

**Key outputs**:
- Final parquet file with columns: `author_did`, `average_toxicity`, `average_outrage`, `total_labeled_posts`
- Results sorted by `total_labeled_posts` descending
- Exported to `results/<timestamp>/aggregated_author_toxicity_outrage.parquet`

**Execution**: Run second to aggregate daily data
```bash
python aggregate_author_to_average_toxicity_across_days.py
```

### 3. `visualize_number_posts_per_author.py`
**Purpose**: Creates visualizations to understand the distribution of posting behavior across authors in the aggregated dataset.

**What it does**:
- Loads the aggregated author-to-average toxicity/outrage data
- Removes outliers using the IQR method (statistically sound box-and-whisker plot definition)
- Creates a histogram showing the distribution of posts per author
- Adds vertical lines marking the top percentiles (0.1%, 1%, 5%, 10%) in different red hues
- Includes comprehensive statistics and insights about posting patterns

**Key outputs**:
- Histogram visualization saved as PNG in `visualizations/number_of_posts_per_author/<timestamp>/`
- Console output with detailed statistics about posting distribution
- Outlier removal statistics and percentile thresholds

**Execution**: Run third to analyze posting patterns
```bash
python visualize_number_posts_per_author.py
```

### 4. `sample_top_users.py`
**Purpose**: Samples the top 10% of users (by post count) for detailed analysis, particularly useful for join date retrieval and correlation analysis.

**What it does**:
- Loads the aggregated author-to-average toxicity/outrage data
- Removes outliers using the same IQR method as the visualization script
- Identifies the top 10% of users by post count (≥77 posts in current dataset)
- Randomly samples 1000 users from this top 10% group
- Saves the sampled data with user DIDs, toxicity/outrage scores, and post counts

**Key outputs**:
- Parquet file with columns: `author_did`, `average_toxicity`, `average_outrage`, `total_labeled_posts`
- Saved to `sampled_users/<timestamp>/top_10_percent_sampled_users.parquet`
- Console output with detailed statistics about the sampling process

**Execution**: Run fourth to prepare user sample for analysis
```bash
python sample_top_users.py
```

### 5. `get_bsky_profiles_for_sampled_users.py`
**Purpose**: Fetches Bluesky profile data for sampled users to obtain join dates and other profile information needed for correlation analysis.

**What it does**:
- Loads the sampled user data from the most recent sampling run
- Checks for existing profile data to avoid re-fetching
- Fetches Bluesky profiles via API using `get_author_record()` from `bluesky_helper.py`
- Processes users in configurable chunks (default: 100) with rate limiting
- Combines toxicity/outrage data with profile information including join dates
- Handles API errors gracefully (invalid DIDs, network issues, etc.)

**Key outputs**:
- Parquet files with columns: `author_did`, `average_toxicity`, `average_outrage`, `total_labeled_posts`, `created_at`, `description`, `display_name`, `followers_count`, `follows_count`, `handle`, `posts_count`
- Saved to `sampled_user_profiles/<timestamp>/user_profiles_chunk_XXX.parquet`
- Console output with detailed progress and summary statistics

**Execution**: Run fifth to fetch profile data for correlation analysis
```bash
python get_bsky_profiles_for_sampled_users.py
```

### 6. `visualize_toxicity_by_join_date.py`
**Purpose**: Analyzes and visualizes toxicity/outrage patterns by user join date to understand how platform behavior correlates with join timing.

**What it does**:
- Loads all profile data from `sampled_user_profiles/` across all timestamp directories
- Converts join dates to YYYY-MM format (groups pre-2024 dates as "2023-12")
- Calculates average toxicity and outrage scores for each join month
- Creates line graphs showing toxicity/outrage trends over time
- Adds vertical red markers for the study period (2024-10 to 2024-12)
- Generates separate and combined visualizations
- Creates user count histogram by join date

**Key outputs**:
- `toxicity_outrage_by_join_date.png` - Separate line plots for toxicity and outrage
- `combined_toxicity_outrage_by_join_date.png` - Combined line plot with dual y-axes
- `user_count_by_join_date.png` - Histogram of user counts by join month
- Saved to `visualizations/toxicity_by_join_date/<timestamp>/`
- Console output with detailed statistics and study period comparisons

**Execution**: Run sixth to analyze toxicity patterns by join date
```bash
python visualize_toxicity_by_join_date.py
```

### 7. `toxicity_outrage_before_after_cutoff_date.py`
**Purpose**: Creates a comparative bar chart analysis of toxicity and outrage levels for users who joined before vs after September 1, 2024.

**What it does**:
- Loads all profile data from `sampled_user_profiles/` across all timestamp directories
- Categorizes users into "Before Sep 1, 2024" and "Sep 1, 2024 or Later" groups
- Calculates average toxicity and outrage scores for each group
- Creates a comparative bar chart with blue color scheme (light blue for before, dark blue for after)
- Handles timezone-aware timestamps gracefully
- Includes value labels on bars and comprehensive statistics

**Key outputs**:
- `before_after_cutoff_comparison.png` - Bar chart comparing toxicity and outrage between groups
- Saved to `visualizations/toxicity_outrage_before_after_cutoff_date/<timestamp>/`
- Console output with detailed group statistics and comparisons

**Execution**: Run seventh to analyze before/after cutoff patterns
```bash
python toxicity_outrage_before_after_cutoff_date.py
```

### Debug Tools

#### `debug_user_join_counts.py`
**Purpose**: Debug visualization to show user join counts by month for troubleshooting data loading issues.

**What it does**:
- Loads all profile data from `sampled_user_profiles/` with detailed logging
- Creates histogram of user counts per join month
- Provides verbose output for debugging data loading across timestamp directories

**Key outputs**:
- Debug histogram saved to `visualizations/debug_join_counts/`
- Detailed console logs showing file loading progress

**Usage**: For troubleshooting data loading issues
```bash
python debug_user_join_counts.py
```

## Data Flow

```
Perspective API Labels + Preprocessed Posts
           ↓
    Daily Processing (get_author_to_average_toxicity_outrage.py)
           ↓
    Daily Author Aggregations (parquet files)
           ↓
    Cross-Day Aggregation (aggregate_author_to_average_toxicity_across_days.py)
           ↓
    Final Weighted Averages (results/<timestamp>/aggregated_author_toxicity_outrage.parquet)
           ↓
    Posting Pattern Analysis (visualize_number_posts_per_author.py)
           ↓
    Distribution Visualizations (visualizations/number_of_posts_per_author/<timestamp>/)
           ↓
    Top User Sampling (sample_top_users.py)
           ↓
    Sampled User Data (sampled_users/<timestamp>/top_10_percent_sampled_users.parquet)
           ↓
    Profile Data Fetching (get_bsky_profiles_for_sampled_users.py)
           ↓
    Combined Toxicity + Profile Data (sampled_user_profiles/<timestamp>/user_profiles_chunk_XXX.parquet)
           ↓
    Join Date Analysis (visualize_toxicity_by_join_date.py)
           ↓
    Toxicity by Join Date Visualizations (visualizations/toxicity_by_join_date/<timestamp>/)
```

## Study Parameters

- **Study Period**: Defined in `services/calculate_analytics/shared/constants.py`
- **Data Sources**: 
  - Perspective API labels (`ml_inference_perspective_api` service)
  - Preprocessed posts (`preprocessed_posts` service)
- **Processing Mode**: Sequential (to avoid memory issues)
- **Output Format**: Parquet files with timestamp-based organization

## Configuration System

The analysis uses a YAML-based configuration system for flexible thresholding and sampling parameters.

### **Configuration File: `sampling_config.yaml`**

**Key Parameters:**
- `threshold_criteria`: "percentile" or "count" - determines thresholding method
- `threshold_value`: Threshold value (percentile % or minimum post count)
- `sample_size`: Number of users to randomly sample
- `remove_outliers`: Whether to remove outliers before thresholding
- `outlier_method`: Method for outlier detection (currently "iqr")

**Example Configurations:**
```yaml
# Run 1 (Top 10% approach)
threshold_criteria: "percentile"
threshold_value: 10
sample_size: 1000

# Run 2 (Count-based approach)
threshold_criteria: "count"
threshold_value: 20
sample_size: 2000
```

### **Thresholding Methods:**
- **Percentile**: Selects top X% of users by post count
- **Count**: Selects users with at least X posts

This system allows for easy experimentation with different sampling strategies without code changes.

## Analysis Runs

This analysis is conducted in multiple batches/runs to manage data processing and API rate limits.

### **Run 1 - Initial Analysis (Completed)**

**Configuration:**
- **Sampling**: Top 10% of users by post count (≥77 posts)
- **Sample Size**: 1,000 randomly sampled users from top 10%
- **Processing**: Sequential mode to avoid memory issues
- **API Chunk Size**: 100 users per batch

**Actual Results:**
- **961 users** successfully analyzed across **12 join date periods**
- **Join date distribution**: 
  - 733 users from 2023-12 (pre-2024 dates grouped together)
  - 228 users from 2024 (distributed across months)
- **Study period users** (2024-10 to 2024-12): 127 users
- **Overall averages**: 0.1045 toxicity, 0.2532 outrage
- **Study period averages**: 0.1058 toxicity, 0.2735 outrage

**Key Findings:**
- Users who joined during the study period show slightly higher toxicity and outrage levels
- Clear temporal patterns visible in the visualization data
- Strong representation of early adopters (pre-2024) vs. later joiners

**Visualizations Generated:**
- `toxicity_outrage_by_join_date.png` - Separate line plots for toxicity and outrage trends
- `combined_toxicity_outrage_by_join_date.png` - Combined visualization with dual y-axes
- `user_count_by_join_date.png` - Histogram showing user distribution by join month
- Debug visualizations for troubleshooting data loading

### **Run 2 - Expanded Analysis (Completed)**

**Configuration:**
- **Sampling**: Users with ≥20 posts (count-based threshold)
- **Sample Size**: 2,000 randomly sampled users
- **Processing**: Sequential mode to avoid memory issues
- **API Chunk Size**: 100 users per batch
- **Configuration**: YAML-based configurable thresholding system

**Actual Results:**
- **2,000 users** successfully sampled from **35,931 eligible users**
- **Original dataset**: 141,159 authors (19M+ posts)
- **After filtering**: 140,159 authors (excluded 1,000 previously sampled)
- **After outlier removal**: 118,754 authors (removed 21,405 outliers)
- **Eligible users** (≥20 posts): 35,931 users
- **Posts range in sample**: 20 - 157 posts
- **Average toxicity**: 0.1014
- **Average outrage**: 0.2478

**Key Findings:**
- Successfully avoided duplicate sampling from Run 1
- Count-based thresholding captured a broader range of users (20-157 posts vs. Run 1's ≥77 posts)
- Similar toxicity/outrage levels to Run 1, suggesting consistency across sampling methods
- Larger sample size (2,000 vs. 1,000) provides more statistical power

**Execution Order for Run 2:**
1. ✅ **Resample Users**: Run `sample_top_users.py` to generate new random sample
2. ✅ **Fetch Profiles**: Run `get_bsky_profiles_for_sampled_users.py` to get join dates
3. ✅ **Analyze Patterns**: Run `visualize_toxicity_by_join_date.py` for visualization
4. **Debug if Needed**: Run `debug_user_join_counts.py` for troubleshooting

**Visualization Results (2025-09-29_10:51:52):**
- **Total users analyzed**: 2,893 (combined from Run 1 and Run 2)
- **Join date periods**: 13 months analyzed
- **Overall average toxicity**: 0.1011
- **Overall average outrage**: 0.2482
- **Join date range**: 2022-11-18 to 2024-11-25
- **Users who joined during study period**: 442
- **Study period avg toxicity**: 0.1035
- **Study period avg outrage**: 0.2699

**Generated Visualizations:**
- `toxicity_outrage_by_join_date.png` - Dual subplot showing toxicity and outrage trends
- `combined_toxicity_outrage_by_join_date.png` - Combined visualization with dual y-axes
- `user_count_by_join_date.png` - Histogram showing user distribution by join month
- `before_after_cutoff_comparison.png` - Bar chart comparing before/after Sep 1, 2024 groups

**Key Findings:**
- Successfully processed 2,893 users from 31 parquet files
- 1 invalid timestamp handled gracefully (labeled as "Unknown")
- Clear visualization of toxicity/outrage patterns by join date
- Study period (Oct-Dec 2024) shows slightly higher outrage levels (0.2699 vs 0.2482 overall)
- Before/After Sep 1, 2024 analysis shows:
  - Before Sep 1, 2024: 2,386 users, avg toxicity 0.1009, avg outrage 0.2436
  - Sep 1, 2024 or Later: 506 users, avg toxicity 0.1024, avg outrage 0.2694
  - Users joining after Sep 1, 2024 show slightly higher outrage levels (0.2694 vs 0.2436)
- Robust error handling prevents crashes from corrupted data files

## Next Steps

### **Immediate Actions:**
1. **Execute Run 2**: Follow the execution order above to generate additional data
2. **Compare Results**: Analyze differences between Run 1 and Run 2 findings
3. **Validate Patterns**: Confirm consistency of toxicity/outrage trends across samples

### **Future Analysis:**
1. **Statistical Analysis**: Determining significance of observed correlations
2. **Further Investigation**: Deeper analysis of specific time periods or user segments
3. **Publication**: Results are ready for research presentation and publication

## Production Execution

Both scripts have corresponding SLURM submission scripts for production runs:
- `submit_toxicity_analysis_prod.sh` - For daily processing
- `submit_toxicity_aggregation_prod.sh` - For aggregation

These scripts handle resource allocation, environment setup, and logging for production-scale analysis.
