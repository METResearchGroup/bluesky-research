{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis\n",
    "\n",
    "Now that we've labeled our data, let's check our results and make some conclusions from it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.metrics import precision_recall_fscore_support"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's load our data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_wd = os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt4_classifications = pd.read_csv(\n",
    "    \"../manuscript_pilot/representative_diversification_feed.csv\"\n",
    ")\n",
    "llama3_8b_classifications = pd.read_csv(\n",
    "    \"classified_posts_llama3_8b.csv\"\n",
    ")\n",
    "llama3_70b_classifications = pd.read_csv(\n",
    "    \"classified_posts_llama3_70b.csv\"\n",
    ")\n",
    "ground_truth_labels = pd.read_csv(\n",
    "    \"../manuscript_pilot/hand_labeled_pilot_posts.csv\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cleaning and preprocessing\n",
    "Now let's do some cleaning and preprocessing so everything is in the same format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### GPT4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt_subset = gpt4_classifications[[\"link\", \"civic\", \"political_ideology\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt_subset[\"civic\"] = gpt_subset[\"civic\"].replace(True, \"civic\")\n",
    "gpt_subset[\"civic\"] = gpt_subset[\"civic\"].replace(False, \"not civic\")\n",
    "gpt_subset[\"political_ideology\"] = gpt_subset[\"political_ideology\"].replace(\n",
    "    \" left-leaning\", \"left-leaning\"\n",
    ")\n",
    "gpt_subset = gpt_subset.rename(\n",
    "    columns={\n",
    "        \"civic\": \"gpt4_civic_label\",\n",
    "        \"political_ideology\": \"gpt4_political_label\"\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['link', 'gpt4_civic_label', 'gpt4_political_label'], dtype='object')"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpt_subset.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Llama models\n",
    "\n",
    "Let's only include the ones that have valid JSON responses, since these are the only ones that we could label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "llama3_8b_subset = llama3_8b_classifications[\n",
    "    llama3_8b_classifications[\"valid_json_response\"] == True\n",
    "]\n",
    "llama3_8b_subset = llama3_8b_subset[\n",
    "    [\"link\", \"civic_label\", \"political_label\"]\n",
    "]\n",
    "llama3_8b_subset = llama3_8b_subset.rename(\n",
    "    columns={\n",
    "        \"civic_label\": \"llama3-8b_civic_label\",\n",
    "        \"political_label\": \"llama3-8b_political_label\"\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['link', 'llama3-8b_civic_label', 'llama3-8b_political_label'], dtype='object')"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llama3_8b_subset.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "llama3_70b_subset = llama3_70b_classifications[\n",
    "    llama3_70b_classifications[\"valid_json_response\"] == True\n",
    "]\n",
    "llama3_70b_subset = llama3_70b_subset[\n",
    "    [\"link\", \"civic_label\", \"political_label\"]\n",
    "]\n",
    "llama3_70b_subset = llama3_70b_subset.rename(\n",
    "    columns={\n",
    "        \"civic_label\": \"llama3-70b_civic_label\",\n",
    "        \"political_label\": \"llama3-70b_political_label\"\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['link', 'llama3-70b_civic_label', 'llama3-70b_political_label'], dtype='object')"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llama3_70b_subset.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Ground-truth labels\n",
    "\n",
    "Let's remove any NAs and then do processing like the others"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "ground_truth_labels = ground_truth_labels[\n",
    "    ~pd.isna(ground_truth_labels[\"civic_hand_label\"])\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "ground_truth_labels_subset = ground_truth_labels[\n",
    "    [\"link\", \"civic_hand_label\", \"political_ideology_hand_label\"]\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now let's get some basic counts and statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GPT4:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "civic\n",
      "not civic    187\n",
      "civic        174\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(gpt_subset[\"gpt4_civic_label\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gpt4_political_label\n",
      "left-leaning     140\n",
      "unclear           18\n",
      "right-leaning     15\n",
      "moderate           1\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    gpt_subset[\n",
    "        gpt_subset[\"gpt4_civic_label\"] == \"civic\"\n",
    "    ][\"gpt4_political_label\"].value_counts()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Llama3-8b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "llama3-8b_civic_label\n",
      "civic        199\n",
      "not civic    148\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(llama3_8b_subset[\"llama3-8b_civic_label\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "llama3-8b_political_label\n",
      "left-leaning     130\n",
      "right-leaning     34\n",
      "unclear           32\n",
      "moderate           3\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    llama3_8b_subset[\n",
    "        llama3_8b_subset[\"llama3-8b_civic_label\"] == \"civic\"\n",
    "    ][\"llama3-8b_political_label\"].value_counts()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Llama3-70b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "llama3-70b_civic_label\n",
      "civic        200\n",
      "not civic    147\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(llama3_70b_subset[\"llama3-70b_civic_label\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "llama3-70b_political_label\n",
      "left-leaning     173\n",
      "right-leaning     11\n",
      "unclear            9\n",
      "moderate           7\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    llama3_70b_subset[\n",
    "        llama3_70b_subset[\"llama3-70b_civic_label\"] == \"civic\"\n",
    "    ][\"llama3-70b_political_label\"].value_counts()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ground truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "civic_hand_label\n",
      "civic        193\n",
      "not civic    161\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(ground_truth_labels_subset[\"civic_hand_label\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "political_ideology_hand_label\n",
      "left-leaning     160\n",
      "unclear           20\n",
      "right-leaning      7\n",
      "moderate           5\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    ground_truth_labels_subset[\n",
    "        ground_truth_labels_subset[\"civic_hand_label\"] == \"civic\"\n",
    "    ][\"political_ideology_hand_label\"].value_counts()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyze the data together\n",
    "\n",
    "Let's join the data together to get a joined version of the labels and the ground truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "joined_df = pd.merge(\n",
    "    gpt_subset, llama3_8b_subset, on=\"link\"\n",
    ")\n",
    "joined_df = pd.merge(\n",
    "    joined_df, llama3_70b_subset, on=\"link\"\n",
    ")\n",
    "joined_df = pd.merge(\n",
    "    joined_df, ground_truth_labels_subset, on=\"link\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(333, 9)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joined_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "joined_df.to_csv(\"posts_with_ground_truth_and_llm_labels.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>link</th>\n",
       "      <th>gpt4_civic_label</th>\n",
       "      <th>gpt4_political_label</th>\n",
       "      <th>llama3-8b_civic_label</th>\n",
       "      <th>llama3-8b_political_label</th>\n",
       "      <th>llama3-70b_civic_label</th>\n",
       "      <th>llama3-70b_political_label</th>\n",
       "      <th>civic_hand_label</th>\n",
       "      <th>political_ideology_hand_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://bsky.app/profile/jbouie.bsky.social/po...</td>\n",
       "      <td>civic</td>\n",
       "      <td>left-leaning</td>\n",
       "      <td>civic</td>\n",
       "      <td>left-leaning</td>\n",
       "      <td>civic</td>\n",
       "      <td>left-leaning</td>\n",
       "      <td>civic</td>\n",
       "      <td>left-leaning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://bsky.app/profile/lethalityjane.bsky.so...</td>\n",
       "      <td>civic</td>\n",
       "      <td>right-leaning</td>\n",
       "      <td>civic</td>\n",
       "      <td>right-leaning</td>\n",
       "      <td>civic</td>\n",
       "      <td>unclear</td>\n",
       "      <td>civic</td>\n",
       "      <td>unclear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://bsky.app/profile/esqueer.bsky.social/p...</td>\n",
       "      <td>civic</td>\n",
       "      <td>left-leaning</td>\n",
       "      <td>civic</td>\n",
       "      <td>left-leaning</td>\n",
       "      <td>civic</td>\n",
       "      <td>left-leaning</td>\n",
       "      <td>civic</td>\n",
       "      <td>left-leaning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://bsky.app/profile/stuflemingnz.bsky.soc...</td>\n",
       "      <td>not civic</td>\n",
       "      <td>NaN</td>\n",
       "      <td>not civic</td>\n",
       "      <td>unclear</td>\n",
       "      <td>not civic</td>\n",
       "      <td>unclear</td>\n",
       "      <td>not civic</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://bsky.app/profile/sararoseg.bsky.social...</td>\n",
       "      <td>civic</td>\n",
       "      <td>left-leaning</td>\n",
       "      <td>civic</td>\n",
       "      <td>left-leaning</td>\n",
       "      <td>civic</td>\n",
       "      <td>left-leaning</td>\n",
       "      <td>civic</td>\n",
       "      <td>left-leaning</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                link gpt4_civic_label  \\\n",
       "0  https://bsky.app/profile/jbouie.bsky.social/po...            civic   \n",
       "1  https://bsky.app/profile/lethalityjane.bsky.so...            civic   \n",
       "2  https://bsky.app/profile/esqueer.bsky.social/p...            civic   \n",
       "3  https://bsky.app/profile/stuflemingnz.bsky.soc...        not civic   \n",
       "4  https://bsky.app/profile/sararoseg.bsky.social...            civic   \n",
       "\n",
       "  gpt4_political_label llama3-8b_civic_label llama3-8b_political_label  \\\n",
       "0         left-leaning                 civic              left-leaning   \n",
       "1        right-leaning                 civic             right-leaning   \n",
       "2         left-leaning                 civic              left-leaning   \n",
       "3                  NaN             not civic                   unclear   \n",
       "4         left-leaning                 civic              left-leaning   \n",
       "\n",
       "  llama3-70b_civic_label llama3-70b_political_label civic_hand_label  \\\n",
       "0                  civic               left-leaning            civic   \n",
       "1                  civic                    unclear            civic   \n",
       "2                  civic               left-leaning            civic   \n",
       "3              not civic                    unclear        not civic   \n",
       "4                  civic               left-leaning            civic   \n",
       "\n",
       "  political_ideology_hand_label  \n",
       "0                  left-leaning  \n",
       "1                       unclear  \n",
       "2                  left-leaning  \n",
       "3                           NaN  \n",
       "4                  left-leaning  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joined_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's make sure that there are no NaN values in the civic columns (\"gpt4_civic_label\", \"llama3-8b_civic_label\", \"llama3-70b_civic_label\", \"civic_hand_label\"). Let's not impute for now, let's just get the counts. \n",
    "\n",
    "Then, Let's also impute any NaNs in the \"gpt4_political_label\", \"political_ideology_hand_label\", \"llama3-8b_political_label\", and \"llama3-70b_political_label\" columns with \"unclear\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NaN counts in civic columns:\n",
      "gpt4_civic_label          0\n",
      "llama3-8b_civic_label     0\n",
      "llama3-70b_civic_label    0\n",
      "civic_hand_label          0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "civic_columns = [\"gpt4_civic_label\", \"llama3-8b_civic_label\", \"llama3-70b_civic_label\", \"civic_hand_label\"]\n",
    "nan_counts_civic = joined_df[civic_columns].isna().sum()\n",
    "print(\"NaN counts in civic columns:\")\n",
    "print(nan_counts_civic)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Verification after imputation:\n",
      "gpt4_political_label             0\n",
      "political_ideology_hand_label    0\n",
      "llama3-8b_political_label        0\n",
      "llama3-70b_political_label       0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "political_columns = [\"gpt4_political_label\", \"political_ideology_hand_label\", \"llama3-8b_political_label\", \"llama3-70b_political_label\"]\n",
    "joined_df[political_columns] = joined_df[political_columns].fillna(\"unclear\")\n",
    "\n",
    "# Verify the imputation\n",
    "print(\"Verification after imputation:\")\n",
    "print(joined_df[political_columns].isna().sum())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we've taken care of the last preprocessing, let's continue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_values = joined_df.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### GPT4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt4_civic_metrics = precision_recall_fscore_support(\n",
    "    y_true=joined_df[\"civic_hand_label\"].tolist(),\n",
    "    y_pred=joined_df[\"gpt4_civic_label\"].tolist(),\n",
    "    average=\"binary\",\n",
    "    pos_label=\"civic\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    gpt4_civic_precision,\n",
    "    gpt4_civic_recall,\n",
    "    gpt4_civic_fbeta_score,\n",
    "    gpt4_civic_support\n",
    ") = gpt4_civic_metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.9426751592356688\tRecall: 0.8222222222222222\tF-1 score: 0.8783382789317508\tSupport: None\n"
     ]
    }
   ],
   "source": [
    "print(f\"Precision: {gpt4_civic_precision}\\tRecall: {gpt4_civic_recall}\\tF-1 score: {gpt4_civic_fbeta_score}\\tSupport: {gpt4_civic_support}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix = pd.crosstab(\n",
    "    joined_df[\"civic_hand_label\"].tolist(),\n",
    "    joined_df[\"gpt4_civic_label\"].tolist()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = (\n",
    "    (confusion_matrix.values[0][0] + confusion_matrix.values[1][1]) \n",
    "    / total_values\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8768768768768769\n"
     ]
    }
   ],
   "source": [
    "print(f\"Accuracy: {acc}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Political ideology classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Llama3-8b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "llama3_8b_civic_metrics = precision_recall_fscore_support(\n",
    "    y_true=joined_df[\"civic_hand_label\"].tolist(),\n",
    "    y_pred=joined_df[\"llama3-8b_civic_label\"].tolist(),\n",
    "    average=\"binary\",\n",
    "    pos_label=\"civic\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>llama3-8b_civic_label</th>\n",
       "      <th>civic</th>\n",
       "      <th>not civic</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>civic_hand_label</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>civic</th>\n",
       "      <td>114</td>\n",
       "      <td>66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>not civic</th>\n",
       "      <td>74</td>\n",
       "      <td>79</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "llama3-8b_civic_label  civic  not civic\n",
       "civic_hand_label                       \n",
       "civic                    114         66\n",
       "not civic                 74         79"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.crosstab(\n",
    "    joined_df[\"civic_hand_label\"],\n",
    "    joined_df[\"llama3-8b_civic_label\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    llama3_8b_civic_precision,\n",
    "    llama3_8b_civic_recall,\n",
    "    llama3_8b_civic_fbeta_score,\n",
    "    llama3_8b_civic_support\n",
    ") = llama3_8b_civic_metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.6063829787234043\tRecall: 0.6333333333333333\tF-1 score: 0.6195652173913043\tSupport: None\n"
     ]
    }
   ],
   "source": [
    "print(f\"Precision: {llama3_8b_civic_precision}\\tRecall: {llama3_8b_civic_recall}\\tF-1 score: {llama3_8b_civic_fbeta_score}\\tSupport: {llama3_8b_civic_support}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Llama3-70b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "llama3_70b_civic_metrics = precision_recall_fscore_support(\n",
    "    y_true=joined_df[\"civic_hand_label\"].tolist(),\n",
    "    y_pred=joined_df[\"llama3-70b_civic_label\"].tolist(),\n",
    "    average=\"binary\",\n",
    "    pos_label=\"civic\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "civic_hand_label\n",
       "civic        180\n",
       "not civic    153\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joined_df[\"civic_hand_label\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "llama3-70b_civic_label\n",
       "civic        189\n",
       "not civic    144\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joined_df[\"llama3-70b_civic_label\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>llama3-70b_civic_label</th>\n",
       "      <th>civic</th>\n",
       "      <th>not civic</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>civic_hand_label</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>civic</th>\n",
       "      <td>112</td>\n",
       "      <td>68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>not civic</th>\n",
       "      <td>77</td>\n",
       "      <td>76</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "llama3-70b_civic_label  civic  not civic\n",
       "civic_hand_label                        \n",
       "civic                     112         68\n",
       "not civic                  77         76"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.crosstab(\n",
    "    joined_df[\"civic_hand_label\"],\n",
    "    joined_df[\"llama3-70b_civic_label\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    llama3_70b_civic_precision,\n",
    "    llama3_70b_civic_recall,\n",
    "    llama3_70b_civic_fbeta_score,\n",
    "    llama3_70b_civic_support\n",
    ") = llama3_70b_civic_metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.5925925925925926\tRecall: 0.6222222222222222\tF-1 score: 0.6070460704607046\tSupport: None\n"
     ]
    }
   ],
   "source": [
    "print(f\"Precision: {llama3_70b_civic_precision}\\tRecall: {llama3_70b_civic_recall}\\tF-1 score: {llama3_70b_civic_fbeta_score}\\tSupport: {llama3_70b_civic_support}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bluesky-research",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
