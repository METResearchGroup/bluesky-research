{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Labeling posts with Llama3-8b via Groq\n",
    "\n",
    "We want to figure out what model would be good for our inference task. We've been experimenting with Llama3-8b via Groq and it seems to perform pretty well for our zero-shot task! Let's see how this performs on our pilot data.\n",
    "\n",
    "We'll use Groq for this, and run it on 300 posts from our pilot data. We'll use the same prompts that we did from our demo Streamlit app.\n",
    "\n",
    "We'll use the LiteLLM [Groq](https://litellm.vercel.app/docs/providers/groq) connection to connect to Groq.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from ml_tooling.llm.inference import run_query\n",
    "from ml_tooling.llm.prompt_helper import generate_complete_prompt_for_post_link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = \"Llama3-8b (via Groq)\"\n",
    "current_wd = os.getcwd()\n",
    "PILOT_DATA_FP = \"../manuscript_pilot/representative_diversification_feed.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pilot_data = pd.read_csv(PILOT_DATA_FP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "bluesky_post_links: list[str] = pilot_data[\"link\"].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_prompts_for_each_link(links: list[str], task_name: str) -> list[str]:\n",
    "    \"\"\"Creates prompts for each link.\"\"\"\n",
    "    res = []\n",
    "    for link in links:\n",
    "        try:\n",
    "            prompt = generate_complete_prompt_for_post_link(link, task_name)\n",
    "            res.append(prompt)\n",
    "        except Exception as e:\n",
    "            print(f\"Error with link {link}: {e}\")\n",
    "            continue\n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll classify civic and political lean in one go. I didn't find any difference between doing it this way vs chaining them (doing civic first and then doing political)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# note: lots of request to Bsky to hydrate post and author info, so needed to\n",
    "# remove the logs from the output. Takes ~4 minutes to run.\n",
    "civic_and_political_lean_prompts = create_prompts_for_each_link(\n",
    "    bluesky_post_links, \"both\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can export these prompts as a .jsonl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "posts_to_classify: list[dict] = [\n",
    "    {\n",
    "        \"link\": link,\n",
    "        \"prompt\": prompt,\n",
    "        \"task_name\": \"Civic and Political Lean\"\n",
    "    }\n",
    "    for (link, prompt) in zip(bluesky_post_links, civic_and_political_lean_prompts)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "jsonl_filename = \"posts_to_classify.jsonl\"\n",
    "jsonl_fp = os.path.join(current_wd, jsonl_filename)\n",
    "\n",
    "with open(jsonl_fp, \"w\") as f:\n",
    "    for post in posts_to_classify:\n",
    "        f.write(f\"{str(post)}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's load the .jsonl to verify that it works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(jsonl_fp, 'r') as f:\n",
    "    lines = f.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "jsons_to_classify: list[dict] = [eval(line) for line in lines]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we know that this works, let's start classifying. Let's first start by doing it on the first prompt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_post = jsons_to_classify[0]\n",
    "example_prompt = example_post[\"prompt\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m20:30:42 - LiteLLM:INFO\u001b[0m: utils.py:1112 - \u001b[92m\n",
      "\n",
      "POST Request Sent from LiteLLM:\n",
      "curl -X POST \\\n",
      "https://api.groq.com/openai/v1/ \\\n",
      "-d '{'model': 'llama3-8b-8192', 'messages': [{'role': 'user', 'content': '\\n\\nPretend that you are a classifier that predicts whether a post has civic content or not. Civic refers to whether a given post is related to politics (government, elections, politicians, activism, etc.) or social issues (major issues that affect a large group of people, such as the economy, inequality, racism, education, immigration, human rights, the environment, etc.). We refer to any content that is classified as being either of these two categories as “civic”; otherwise they are not civic. Please classify the following text denoted in <text> as \"civic\" or \"not civic\". \\n\\nThen, if the post is civic, classify the text based on the political lean of the opinion or argument it presents. Your options are \\'left-leaning\\', \\'moderate\\', \\'right-leaning\\', or \\'unclear\\'. You are analyzing text that has been pre-identified as \\'political\\' in nature. If the text is not civic, return \"unclear\".\\n\\nThink through your response step by step.\\n\\nReturn in a JSON format in the following way:\\n{\\n    \"civic\": <two values, \\'civic\\' or \\'not civic\\'>,\\n    \"political_ideology\": <four values, \\'left-leaning\\', \\'moderate\\', \\'right-leaning\\', \\'unclear\\'>,\\n    \"reason_civic\": <optional, a 1 sentence reason for why the text is civic>,\\n    \"reason_political_ideology\": <optional, a 1 sentence reason for why the text has the given political ideology>\\n}\\n\\n\\nHere is the post text that needs to be classified:\\n```\\n<text>\\nthat’s right. there is a lot of very good evidence that americans are just as productive with a four-day work week and much happier to boot. what’s the point of having such a wealth society if we are not going to try to benefit from it?\\n```\\n\\n\\nThe classification of a post might depend on contextual information. For example, the text in a post might comment on an image or on a retweeted post. Attend to the context where appropriate. Here is some context on the post that needs classification: ```\\n<Content referenced or linked to in the post>\\n \\nThe post contains a external link to content with the following details:\\n```\\n[title]: Bernie Sanders Proposes Reducing Americans’ Workweek to 32 Hours\\n[description]: His proposal would pare down the workweek over a four-year period. The 40-hour workweek has stood as the standard in the U.S. since it became enshrined in federal law in 1940.\\n```\\n\\n<URLs>\\n The post links to external URLs:\\nThis post links to a trustworthy news article.\\n\\n\\n```\\nAgain, the text of the post that needs to be classified is:\\n```\\n<text>\\nthat’s right. there is a lot of very good evidence that americans are just as productive with a four-day work week and much happier to boot. what’s the point of having such a wealth society if we are not going to try to benefit from it?\\n```\\n\\nJustifications are not necessary.\\n'}], 'temperature': 0.0, 'extra_body': {}}'\n",
      "\u001b[0m\n",
      "\n",
      "\u001b[92m\n",
      "\n",
      "POST Request Sent from LiteLLM:\n",
      "curl -X POST \\\n",
      "https://api.groq.com/openai/v1/ \\\n",
      "-d '{'model': 'llama3-8b-8192', 'messages': [{'role': 'user', 'content': '\\n\\nPretend that you are a classifier that predicts whether a post has civic content or not. Civic refers to whether a given post is related to politics (government, elections, politicians, activism, etc.) or social issues (major issues that affect a large group of people, such as the economy, inequality, racism, education, immigration, human rights, the environment, etc.). We refer to any content that is classified as being either of these two categories as “civic”; otherwise they are not civic. Please classify the following text denoted in <text> as \"civic\" or \"not civic\". \\n\\nThen, if the post is civic, classify the text based on the political lean of the opinion or argument it presents. Your options are \\'left-leaning\\', \\'moderate\\', \\'right-leaning\\', or \\'unclear\\'. You are analyzing text that has been pre-identified as \\'political\\' in nature. If the text is not civic, return \"unclear\".\\n\\nThink through your response step by step.\\n\\nReturn in a JSON format in the following way:\\n{\\n    \"civic\": <two values, \\'civic\\' or \\'not civic\\'>,\\n    \"political_ideology\": <four values, \\'left-leaning\\', \\'moderate\\', \\'right-leaning\\', \\'unclear\\'>,\\n    \"reason_civic\": <optional, a 1 sentence reason for why the text is civic>,\\n    \"reason_political_ideology\": <optional, a 1 sentence reason for why the text has the given political ideology>\\n}\\n\\n\\nHere is the post text that needs to be classified:\\n```\\n<text>\\nthat’s right. there is a lot of very good evidence that americans are just as productive with a four-day work week and much happier to boot. what’s the point of having such a wealth society if we are not going to try to benefit from it?\\n```\\n\\n\\nThe classification of a post might depend on contextual information. For example, the text in a post might comment on an image or on a retweeted post. Attend to the context where appropriate. Here is some context on the post that needs classification: ```\\n<Content referenced or linked to in the post>\\n \\nThe post contains a external link to content with the following details:\\n```\\n[title]: Bernie Sanders Proposes Reducing Americans’ Workweek to 32 Hours\\n[description]: His proposal would pare down the workweek over a four-year period. The 40-hour workweek has stood as the standard in the U.S. since it became enshrined in federal law in 1940.\\n```\\n\\n<URLs>\\n The post links to external URLs:\\nThis post links to a trustworthy news article.\\n\\n\\n```\\nAgain, the text of the post that needs to be classified is:\\n```\\n<text>\\nthat’s right. there is a lot of very good evidence that americans are just as productive with a four-day work week and much happier to boot. what’s the point of having such a wealth society if we are not going to try to benefit from it?\\n```\\n\\nJustifications are not necessary.\\n'}], 'temperature': 0.0, 'extra_body': {}}'\n",
      "\u001b[0m\n",
      "\n",
      "HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m20:30:43 - LiteLLM:INFO\u001b[0m: utils.py:2878 - Wrapper: Completed Call, calling success_handler\n",
      "Wrapper: Completed Call, calling success_handler\n"
     ]
    }
   ],
   "source": [
    "example_result = run_query(\n",
    "    prompt=example_prompt, model_name=MODEL_NAME\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Here is the classification result in JSON format:\\n\\n{\\n    \"civic\": \"civic\",\\n    \"political_ideology\": \"left-leaning\",\\n    \"reason_civic\": \"The post references a specific policy proposal by Bernie Sanders, a left-leaning politician, and discusses the benefits of a four-day workweek.\",\\n    \"reason_political_ideology\": \"The post\\'s language and tone, as well as its reference to a left-leaning politician\\'s proposal, suggest a left-leaning political ideology.\"\\n}'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want something that has a nicer printing. Ideally it also only returns the JSON format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here is the classification result in JSON format:\n",
      "\n",
      "{\n",
      "    \"civic\": \"civic\",\n",
      "    \"political_ideology\": \"left-leaning\",\n",
      "    \"reason_civic\": \"The post references a specific policy proposal by Bernie Sanders, a left-leaning politician, and discusses the benefits of a four-day workweek.\",\n",
      "    \"reason_political_ideology\": \"The post's language and tone, as well as its reference to a left-leaning politician's proposal, suggest a left-leaning political ideology.\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(example_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try the next result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "second_prompt = jsons_to_classify[1][\"prompt\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m20:32:13 - LiteLLM:INFO\u001b[0m: utils.py:1112 - \u001b[92m\n",
      "\n",
      "POST Request Sent from LiteLLM:\n",
      "curl -X POST \\\n",
      "https://api.groq.com/openai/v1/ \\\n",
      "-d '{'model': 'llama3-8b-8192', 'messages': [{'role': 'user', 'content': '\\n\\nPretend that you are a classifier that predicts whether a post has civic content or not. Civic refers to whether a given post is related to politics (government, elections, politicians, activism, etc.) or social issues (major issues that affect a large group of people, such as the economy, inequality, racism, education, immigration, human rights, the environment, etc.). We refer to any content that is classified as being either of these two categories as “civic”; otherwise they are not civic. Please classify the following text denoted in <text> as \"civic\" or \"not civic\". \\n\\nThen, if the post is civic, classify the text based on the political lean of the opinion or argument it presents. Your options are \\'left-leaning\\', \\'moderate\\', \\'right-leaning\\', or \\'unclear\\'. You are analyzing text that has been pre-identified as \\'political\\' in nature. If the text is not civic, return \"unclear\".\\n\\nThink through your response step by step.\\n\\nReturn in a JSON format in the following way:\\n{\\n    \"civic\": <two values, \\'civic\\' or \\'not civic\\'>,\\n    \"political_ideology\": <four values, \\'left-leaning\\', \\'moderate\\', \\'right-leaning\\', \\'unclear\\'>,\\n    \"reason_civic\": <optional, a 1 sentence reason for why the text is civic>,\\n    \"reason_political_ideology\": <optional, a 1 sentence reason for why the text has the given political ideology>\\n}\\n\\n\\nHere is the post text that needs to be classified:\\n```\\n<text>\\nThe hill I will die on is that this is not a digital problem. We don\\'t send younger kids out to play by themselves anymore for fear of kidnapping/CPS, and those kids become teens who don\\'t do it either. There\\'s also a loss of third spaces for teens. Even the freaking malls require chaperones.\\n```\\n\\n\\nThe classification of a post might depend on contextual information. For example, the text in a post might comment on an image or on a retweeted post. Attend to the context where appropriate. Here is some context on the post that needs classification: ```\\n<Content referenced or linked to in the post>\\n \\nThe post contains the following alt text for its images:\\n```\\nImage 1 alt text: Tweet with a graph showing a decline of teenagers who say they go out with friends two or more times a week.\\n\\n```\\n\\n\\n```\\nAgain, the text of the post that needs to be classified is:\\n```\\n<text>\\nThe hill I will die on is that this is not a digital problem. We don\\'t send younger kids out to play by themselves anymore for fear of kidnapping/CPS, and those kids become teens who don\\'t do it either. There\\'s also a loss of third spaces for teens. Even the freaking malls require chaperones.\\n```\\n\\nJustifications are not necessary.\\n'}], 'temperature': 0.0, 'extra_body': {}}'\n",
      "\u001b[0m\n",
      "\n",
      "\u001b[92m\n",
      "\n",
      "POST Request Sent from LiteLLM:\n",
      "curl -X POST \\\n",
      "https://api.groq.com/openai/v1/ \\\n",
      "-d '{'model': 'llama3-8b-8192', 'messages': [{'role': 'user', 'content': '\\n\\nPretend that you are a classifier that predicts whether a post has civic content or not. Civic refers to whether a given post is related to politics (government, elections, politicians, activism, etc.) or social issues (major issues that affect a large group of people, such as the economy, inequality, racism, education, immigration, human rights, the environment, etc.). We refer to any content that is classified as being either of these two categories as “civic”; otherwise they are not civic. Please classify the following text denoted in <text> as \"civic\" or \"not civic\". \\n\\nThen, if the post is civic, classify the text based on the political lean of the opinion or argument it presents. Your options are \\'left-leaning\\', \\'moderate\\', \\'right-leaning\\', or \\'unclear\\'. You are analyzing text that has been pre-identified as \\'political\\' in nature. If the text is not civic, return \"unclear\".\\n\\nThink through your response step by step.\\n\\nReturn in a JSON format in the following way:\\n{\\n    \"civic\": <two values, \\'civic\\' or \\'not civic\\'>,\\n    \"political_ideology\": <four values, \\'left-leaning\\', \\'moderate\\', \\'right-leaning\\', \\'unclear\\'>,\\n    \"reason_civic\": <optional, a 1 sentence reason for why the text is civic>,\\n    \"reason_political_ideology\": <optional, a 1 sentence reason for why the text has the given political ideology>\\n}\\n\\n\\nHere is the post text that needs to be classified:\\n```\\n<text>\\nThe hill I will die on is that this is not a digital problem. We don\\'t send younger kids out to play by themselves anymore for fear of kidnapping/CPS, and those kids become teens who don\\'t do it either. There\\'s also a loss of third spaces for teens. Even the freaking malls require chaperones.\\n```\\n\\n\\nThe classification of a post might depend on contextual information. For example, the text in a post might comment on an image or on a retweeted post. Attend to the context where appropriate. Here is some context on the post that needs classification: ```\\n<Content referenced or linked to in the post>\\n \\nThe post contains the following alt text for its images:\\n```\\nImage 1 alt text: Tweet with a graph showing a decline of teenagers who say they go out with friends two or more times a week.\\n\\n```\\n\\n\\n```\\nAgain, the text of the post that needs to be classified is:\\n```\\n<text>\\nThe hill I will die on is that this is not a digital problem. We don\\'t send younger kids out to play by themselves anymore for fear of kidnapping/CPS, and those kids become teens who don\\'t do it either. There\\'s also a loss of third spaces for teens. Even the freaking malls require chaperones.\\n```\\n\\nJustifications are not necessary.\\n'}], 'temperature': 0.0, 'extra_body': {}}'\n",
      "\u001b[0m\n",
      "\n",
      "HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m20:32:14 - LiteLLM:INFO\u001b[0m: utils.py:2878 - Wrapper: Completed Call, calling success_handler\n",
      "Wrapper: Completed Call, calling success_handler\n"
     ]
    }
   ],
   "source": [
    "second_result = run_query(\n",
    "    prompt=second_prompt, model_name=MODEL_NAME\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Here is the classification result in JSON format:\\n\\n{\\n    \"civic\": \"civic\",\\n    \"political_ideology\": \"right-leaning\",\\n    \"reason_civic\": \"The post discusses social issues such as fear of kidnapping/CPS and loss of third spaces for teens, which are civic topics.\",\\n    \"reason_political_ideology\": \"The post\\'s emphasis on individual responsibility and parental protectionism is characteristic of right-leaning ideology.\"\\n}\\n\\nNote that I classified the post as \"civic\" because it discusses social issues that affect a large group of people, such as fear of kidnapping/CPS and loss of third spaces for teens. I classified the post as \"right-leaning\" because it emphasizes individual responsibility and parental protectionism, which are characteristic of right-leaning ideology.'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "second_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try to prompt the model to return only JSON format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "second_prompt = (\n",
    "    second_prompt + \"\\nReturn ONLY the JSON. I will parse the string result in JSON format.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m20:33:35 - LiteLLM:INFO\u001b[0m: utils.py:1112 - \u001b[92m\n",
      "\n",
      "POST Request Sent from LiteLLM:\n",
      "curl -X POST \\\n",
      "https://api.groq.com/openai/v1/ \\\n",
      "-d '{'model': 'llama3-8b-8192', 'messages': [{'role': 'user', 'content': '\\n\\nPretend that you are a classifier that predicts whether a post has civic content or not. Civic refers to whether a given post is related to politics (government, elections, politicians, activism, etc.) or social issues (major issues that affect a large group of people, such as the economy, inequality, racism, education, immigration, human rights, the environment, etc.). We refer to any content that is classified as being either of these two categories as “civic”; otherwise they are not civic. Please classify the following text denoted in <text> as \"civic\" or \"not civic\". \\n\\nThen, if the post is civic, classify the text based on the political lean of the opinion or argument it presents. Your options are \\'left-leaning\\', \\'moderate\\', \\'right-leaning\\', or \\'unclear\\'. You are analyzing text that has been pre-identified as \\'political\\' in nature. If the text is not civic, return \"unclear\".\\n\\nThink through your response step by step.\\n\\nReturn in a JSON format in the following way:\\n{\\n    \"civic\": <two values, \\'civic\\' or \\'not civic\\'>,\\n    \"political_ideology\": <four values, \\'left-leaning\\', \\'moderate\\', \\'right-leaning\\', \\'unclear\\'>,\\n    \"reason_civic\": <optional, a 1 sentence reason for why the text is civic>,\\n    \"reason_political_ideology\": <optional, a 1 sentence reason for why the text has the given political ideology>\\n}\\n\\n\\nHere is the post text that needs to be classified:\\n```\\n<text>\\nThe hill I will die on is that this is not a digital problem. We don\\'t send younger kids out to play by themselves anymore for fear of kidnapping/CPS, and those kids become teens who don\\'t do it either. There\\'s also a loss of third spaces for teens. Even the freaking malls require chaperones.\\n```\\n\\n\\nThe classification of a post might depend on contextual information. For example, the text in a post might comment on an image or on a retweeted post. Attend to the context where appropriate. Here is some context on the post that needs classification: ```\\n<Content referenced or linked to in the post>\\n \\nThe post contains the following alt text for its images:\\n```\\nImage 1 alt text: Tweet with a graph showing a decline of teenagers who say they go out with friends two or more times a week.\\n\\n```\\n\\n\\n```\\nAgain, the text of the post that needs to be classified is:\\n```\\n<text>\\nThe hill I will die on is that this is not a digital problem. We don\\'t send younger kids out to play by themselves anymore for fear of kidnapping/CPS, and those kids become teens who don\\'t do it either. There\\'s also a loss of third spaces for teens. Even the freaking malls require chaperones.\\n```\\n\\nJustifications are not necessary.\\n\\nReturn ONLY the JSON. I will parse the string result in JSON format.'}], 'temperature': 0.0, 'extra_body': {}}'\n",
      "\u001b[0m\n",
      "\n",
      "\u001b[92m\n",
      "\n",
      "POST Request Sent from LiteLLM:\n",
      "curl -X POST \\\n",
      "https://api.groq.com/openai/v1/ \\\n",
      "-d '{'model': 'llama3-8b-8192', 'messages': [{'role': 'user', 'content': '\\n\\nPretend that you are a classifier that predicts whether a post has civic content or not. Civic refers to whether a given post is related to politics (government, elections, politicians, activism, etc.) or social issues (major issues that affect a large group of people, such as the economy, inequality, racism, education, immigration, human rights, the environment, etc.). We refer to any content that is classified as being either of these two categories as “civic”; otherwise they are not civic. Please classify the following text denoted in <text> as \"civic\" or \"not civic\". \\n\\nThen, if the post is civic, classify the text based on the political lean of the opinion or argument it presents. Your options are \\'left-leaning\\', \\'moderate\\', \\'right-leaning\\', or \\'unclear\\'. You are analyzing text that has been pre-identified as \\'political\\' in nature. If the text is not civic, return \"unclear\".\\n\\nThink through your response step by step.\\n\\nReturn in a JSON format in the following way:\\n{\\n    \"civic\": <two values, \\'civic\\' or \\'not civic\\'>,\\n    \"political_ideology\": <four values, \\'left-leaning\\', \\'moderate\\', \\'right-leaning\\', \\'unclear\\'>,\\n    \"reason_civic\": <optional, a 1 sentence reason for why the text is civic>,\\n    \"reason_political_ideology\": <optional, a 1 sentence reason for why the text has the given political ideology>\\n}\\n\\n\\nHere is the post text that needs to be classified:\\n```\\n<text>\\nThe hill I will die on is that this is not a digital problem. We don\\'t send younger kids out to play by themselves anymore for fear of kidnapping/CPS, and those kids become teens who don\\'t do it either. There\\'s also a loss of third spaces for teens. Even the freaking malls require chaperones.\\n```\\n\\n\\nThe classification of a post might depend on contextual information. For example, the text in a post might comment on an image or on a retweeted post. Attend to the context where appropriate. Here is some context on the post that needs classification: ```\\n<Content referenced or linked to in the post>\\n \\nThe post contains the following alt text for its images:\\n```\\nImage 1 alt text: Tweet with a graph showing a decline of teenagers who say they go out with friends two or more times a week.\\n\\n```\\n\\n\\n```\\nAgain, the text of the post that needs to be classified is:\\n```\\n<text>\\nThe hill I will die on is that this is not a digital problem. We don\\'t send younger kids out to play by themselves anymore for fear of kidnapping/CPS, and those kids become teens who don\\'t do it either. There\\'s also a loss of third spaces for teens. Even the freaking malls require chaperones.\\n```\\n\\nJustifications are not necessary.\\n\\nReturn ONLY the JSON. I will parse the string result in JSON format.'}], 'temperature': 0.0, 'extra_body': {}}'\n",
      "\u001b[0m\n",
      "\n",
      "HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m20:33:35 - LiteLLM:INFO\u001b[0m: utils.py:2878 - Wrapper: Completed Call, calling success_handler\n",
      "Wrapper: Completed Call, calling success_handler\n"
     ]
    }
   ],
   "source": [
    "second_result = run_query(\n",
    "    prompt=second_prompt, model_name=MODEL_NAME\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"civic\": \"civic\",\n",
      "    \"political_ideology\": \"right-leaning\",\n",
      "    \"reason_civic\": \"The post discusses social issues affecting teenagers, such as the decline of third spaces and the impact of fear on their social behavior.\",\n",
      "    \"reason_political_ideology\": \"The post's emphasis on individual responsibility and the need for parental supervision suggests a right-leaning perspective.\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(second_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "second_result_dict: dict = eval(second_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'civic': 'civic',\n",
       " 'political_ideology': 'right-leaning',\n",
       " 'reason_civic': 'The post discusses social issues affecting teenagers, such as the decline of third spaces and the impact of fear on their social behavior.',\n",
       " 'reason_political_ideology': \"The post's emphasis on individual responsibility and the need for parental supervision suggests a right-leaning perspective.\"}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "second_result_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's go back and add this string command to all the prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "for post in jsons_to_classify:\n",
    "    post[\"prompt\"] = post[\"prompt\"] + \"\\nReturn ONLY the JSON. I will parse the string result in JSON format.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Pretend that you are a classifier that predicts whether a post has civic content or not. Civic refers to whether a given post is related to politics (government, elections, politicians, activism, etc.) or social issues (major issues that affect a large group of people, such as the economy, inequality, racism, education, immigration, human rights, the environment, etc.). We refer to any content that is classified as being either of these two categories as “civic”; otherwise they are not civic. Please classify the following text denoted in <text> as \"civic\" or \"not civic\". \n",
      "\n",
      "Then, if the post is civic, classify the text based on the political lean of the opinion or argument it presents. Your options are 'left-leaning', 'moderate', 'right-leaning', or 'unclear'. You are analyzing text that has been pre-identified as 'political' in nature. If the text is not civic, return \"unclear\".\n",
      "\n",
      "Think through your response step by step.\n",
      "\n",
      "Return in a JSON format in the following way:\n",
      "{\n",
      "    \"civic\": <two values, 'civic' or 'not civic'>,\n",
      "    \"political_ideology\": <four values, 'left-leaning', 'moderate', 'right-leaning', 'unclear'>,\n",
      "    \"reason_civic\": <optional, a 1 sentence reason for why the text is civic>,\n",
      "    \"reason_political_ideology\": <optional, a 1 sentence reason for why the text has the given political ideology>\n",
      "}\n",
      "\n",
      "\n",
      "Here is the post text that needs to be classified:\n",
      "```\n",
      "<text>\n",
      "that’s right. there is a lot of very good evidence that americans are just as productive with a four-day work week and much happier to boot. what’s the point of having such a wealth society if we are not going to try to benefit from it?\n",
      "```\n",
      "\n",
      "\n",
      "The classification of a post might depend on contextual information. For example, the text in a post might comment on an image or on a retweeted post. Attend to the context where appropriate. Here is some context on the post that needs classification: ```\n",
      "<Content referenced or linked to in the post>\n",
      " \n",
      "The post contains a external link to content with the following details:\n",
      "```\n",
      "[title]: Bernie Sanders Proposes Reducing Americans’ Workweek to 32 Hours\n",
      "[description]: His proposal would pare down the workweek over a four-year period. The 40-hour workweek has stood as the standard in the U.S. since it became enshrined in federal law in 1940.\n",
      "```\n",
      "\n",
      "<URLs>\n",
      " The post links to external URLs:\n",
      "This post links to a trustworthy news article.\n",
      "\n",
      "\n",
      "```\n",
      "Again, the text of the post that needs to be classified is:\n",
      "```\n",
      "<text>\n",
      "that’s right. there is a lot of very good evidence that americans are just as productive with a four-day work week and much happier to boot. what’s the point of having such a wealth society if we are not going to try to benefit from it?\n",
      "```\n",
      "\n",
      "Justifications are not necessary.\n",
      "\n",
      "Return ONLY the JSON. I will parse the string result in JSON format.\n"
     ]
    }
   ],
   "source": [
    "print(jsons_to_classify[0][\"prompt\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's export these"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "jsonl_filename = \"posts_to_classify.jsonl\"\n",
    "jsonl_fp = os.path.join(current_wd, jsonl_filename)\n",
    "\n",
    "with open(jsonl_fp, \"w\") as f:\n",
    "    for post in jsons_to_classify:\n",
    "        f.write(f\"{str(post)}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's rerun our inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m20:38:03 - LiteLLM:INFO\u001b[0m: utils.py:1112 - \u001b[92m\n",
      "\n",
      "POST Request Sent from LiteLLM:\n",
      "curl -X POST \\\n",
      "https://api.groq.com/openai/v1/ \\\n",
      "-d '{'model': 'llama3-8b-8192', 'messages': [{'role': 'user', 'content': '\\n\\nPretend that you are a classifier that predicts whether a post has civic content or not. Civic refers to whether a given post is related to politics (government, elections, politicians, activism, etc.) or social issues (major issues that affect a large group of people, such as the economy, inequality, racism, education, immigration, human rights, the environment, etc.). We refer to any content that is classified as being either of these two categories as “civic”; otherwise they are not civic. Please classify the following text denoted in <text> as \"civic\" or \"not civic\". \\n\\nThen, if the post is civic, classify the text based on the political lean of the opinion or argument it presents. Your options are \\'left-leaning\\', \\'moderate\\', \\'right-leaning\\', or \\'unclear\\'. You are analyzing text that has been pre-identified as \\'political\\' in nature. If the text is not civic, return \"unclear\".\\n\\nThink through your response step by step.\\n\\nReturn in a JSON format in the following way:\\n{\\n    \"civic\": <two values, \\'civic\\' or \\'not civic\\'>,\\n    \"political_ideology\": <four values, \\'left-leaning\\', \\'moderate\\', \\'right-leaning\\', \\'unclear\\'>,\\n    \"reason_civic\": <optional, a 1 sentence reason for why the text is civic>,\\n    \"reason_political_ideology\": <optional, a 1 sentence reason for why the text has the given political ideology>\\n}\\n\\n\\nHere is the post text that needs to be classified:\\n```\\n<text>\\nIt would be so cool if laws existed for Elon Musk\\n```\\n\\n\\nThe classification of a post might depend on contextual information. For example, the text in a post might comment on an image or on a retweeted post. Attend to the context where appropriate. Here is some context on the post that needs classification: ```\\n<Content referenced or linked to in the post>\\n \\nThe post references another post with the following details:\\n```\\n\\n[embedded record text]: The Musk Foundation is one of the US\\'s largest charities and Elon Musk has received huge tax benefits. But the foundation isn\\'t doling out as much $ as is legally required.\\n\\nWhen it does give, that $ often goes to causes benefitting his own interests. We investigated: www.nytimes.com/2024/03/10/u...\\n```\\n\\n\\n```\\nAgain, the text of the post that needs to be classified is:\\n```\\n<text>\\nIt would be so cool if laws existed for Elon Musk\\n```\\n\\nJustifications are not necessary.\\n\\nReturn ONLY the JSON. I will parse the string result in JSON format.'}], 'temperature': 0.0, 'extra_body': {}}'\n",
      "\u001b[0m\n",
      "\n",
      "\u001b[92m\n",
      "\n",
      "POST Request Sent from LiteLLM:\n",
      "curl -X POST \\\n",
      "https://api.groq.com/openai/v1/ \\\n",
      "-d '{'model': 'llama3-8b-8192', 'messages': [{'role': 'user', 'content': '\\n\\nPretend that you are a classifier that predicts whether a post has civic content or not. Civic refers to whether a given post is related to politics (government, elections, politicians, activism, etc.) or social issues (major issues that affect a large group of people, such as the economy, inequality, racism, education, immigration, human rights, the environment, etc.). We refer to any content that is classified as being either of these two categories as “civic”; otherwise they are not civic. Please classify the following text denoted in <text> as \"civic\" or \"not civic\". \\n\\nThen, if the post is civic, classify the text based on the political lean of the opinion or argument it presents. Your options are \\'left-leaning\\', \\'moderate\\', \\'right-leaning\\', or \\'unclear\\'. You are analyzing text that has been pre-identified as \\'political\\' in nature. If the text is not civic, return \"unclear\".\\n\\nThink through your response step by step.\\n\\nReturn in a JSON format in the following way:\\n{\\n    \"civic\": <two values, \\'civic\\' or \\'not civic\\'>,\\n    \"political_ideology\": <four values, \\'left-leaning\\', \\'moderate\\', \\'right-leaning\\', \\'unclear\\'>,\\n    \"reason_civic\": <optional, a 1 sentence reason for why the text is civic>,\\n    \"reason_political_ideology\": <optional, a 1 sentence reason for why the text has the given political ideology>\\n}\\n\\n\\nHere is the post text that needs to be classified:\\n```\\n<text>\\nIt would be so cool if laws existed for Elon Musk\\n```\\n\\n\\nThe classification of a post might depend on contextual information. For example, the text in a post might comment on an image or on a retweeted post. Attend to the context where appropriate. Here is some context on the post that needs classification: ```\\n<Content referenced or linked to in the post>\\n \\nThe post references another post with the following details:\\n```\\n\\n[embedded record text]: The Musk Foundation is one of the US\\'s largest charities and Elon Musk has received huge tax benefits. But the foundation isn\\'t doling out as much $ as is legally required.\\n\\nWhen it does give, that $ often goes to causes benefitting his own interests. We investigated: www.nytimes.com/2024/03/10/u...\\n```\\n\\n\\n```\\nAgain, the text of the post that needs to be classified is:\\n```\\n<text>\\nIt would be so cool if laws existed for Elon Musk\\n```\\n\\nJustifications are not necessary.\\n\\nReturn ONLY the JSON. I will parse the string result in JSON format.'}], 'temperature': 0.0, 'extra_body': {}}'\n",
      "\u001b[0m\n",
      "\n",
      "HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m20:38:03 - LiteLLM:INFO\u001b[0m: utils.py:2878 - Wrapper: Completed Call, calling success_handler\n",
      "Wrapper: Completed Call, calling success_handler\n"
     ]
    }
   ],
   "source": [
    "example_post = jsons_to_classify[100]\n",
    "example_prompt = example_post[\"prompt\"]\n",
    "example_result = run_query(\n",
    "    prompt=example_prompt, model_name=MODEL_NAME\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_res: dict = eval(example_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'civic': 'civic',\n",
       " 'political_ideology': 'left-leaning',\n",
       " 'reason_civic': \"The post references a news article about Elon Musk's charity and tax benefits, indicating a civic concern about government policies and philanthropy.\",\n",
       " 'reason_political_ideology': \"The post's tone and language, such as 'it would be cool if laws existed', suggests a left-leaning perspective critical of wealth inequality and corporate influence.\"}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great! Let's run this at scale now. Let's also save our intermediate results to see how they do."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "inference_results: list[str] = []\n",
    "total_num_posts = len(jsons_to_classify)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# note: this inferacts with the Groq API directly, so this will cost money.\n",
    "# rate limit is 30 requests/min (https://console.groq.com/settings/limits)\n",
    "# in total, this took ~16 minutes.\n",
    "for idx, post in enumerate(jsons_to_classify):\n",
    "    if idx % 50 == 0:\n",
    "        print(f\"Processing post {idx + 1} of {total_num_posts}\")\n",
    "    try:\n",
    "        post_result = run_query(\n",
    "            prompt=post[\"prompt\"], model_name=MODEL_NAME\n",
    "        )\n",
    "        inference_results.append(post_result)\n",
    "    except Exception as e:\n",
    "        print(f\"Error with post {idx + 1}: {e}\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see how it did"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = eval(inference_results[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'civic': 'civic',\n",
       " 'political_ideology': 'left-leaning',\n",
       " 'reason_civic': 'The post references a specific policy proposal by a politician (Bernie Sanders) and discusses its potential benefits.',\n",
       " 'reason_political_ideology': \"The post's tone and language, as well as its reference to a left-leaning politician's proposal, suggest a left-leaning political ideology.\"}"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "classified_results: list[dict] = [\n",
    "    {\n",
    "        **post, \"result\": result\n",
    "    }\n",
    "    for (post, result) in zip(jsons_to_classify, inference_results)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'link': 'https://bsky.app/profile/jbouie.bsky.social/post/3knqbtrdzrz2n',\n",
       " 'prompt': '\\n\\nPretend that you are a classifier that predicts whether a post has civic content or not. Civic refers to whether a given post is related to politics (government, elections, politicians, activism, etc.) or social issues (major issues that affect a large group of people, such as the economy, inequality, racism, education, immigration, human rights, the environment, etc.). We refer to any content that is classified as being either of these two categories as “civic”; otherwise they are not civic. Please classify the following text denoted in <text> as \"civic\" or \"not civic\". \\n\\nThen, if the post is civic, classify the text based on the political lean of the opinion or argument it presents. Your options are \\'left-leaning\\', \\'moderate\\', \\'right-leaning\\', or \\'unclear\\'. You are analyzing text that has been pre-identified as \\'political\\' in nature. If the text is not civic, return \"unclear\".\\n\\nThink through your response step by step.\\n\\nReturn in a JSON format in the following way:\\n{\\n    \"civic\": <two values, \\'civic\\' or \\'not civic\\'>,\\n    \"political_ideology\": <four values, \\'left-leaning\\', \\'moderate\\', \\'right-leaning\\', \\'unclear\\'>,\\n    \"reason_civic\": <optional, a 1 sentence reason for why the text is civic>,\\n    \"reason_political_ideology\": <optional, a 1 sentence reason for why the text has the given political ideology>\\n}\\n\\n\\nHere is the post text that needs to be classified:\\n```\\n<text>\\nthat’s right. there is a lot of very good evidence that americans are just as productive with a four-day work week and much happier to boot. what’s the point of having such a wealth society if we are not going to try to benefit from it?\\n```\\n\\n\\nThe classification of a post might depend on contextual information. For example, the text in a post might comment on an image or on a retweeted post. Attend to the context where appropriate. Here is some context on the post that needs classification: ```\\n<Content referenced or linked to in the post>\\n \\nThe post contains a external link to content with the following details:\\n```\\n[title]: Bernie Sanders Proposes Reducing Americans’ Workweek to 32 Hours\\n[description]: His proposal would pare down the workweek over a four-year period. The 40-hour workweek has stood as the standard in the U.S. since it became enshrined in federal law in 1940.\\n```\\n\\n<URLs>\\n The post links to external URLs:\\nThis post links to a trustworthy news article.\\n\\n\\n```\\nAgain, the text of the post that needs to be classified is:\\n```\\n<text>\\nthat’s right. there is a lot of very good evidence that americans are just as productive with a four-day work week and much happier to boot. what’s the point of having such a wealth society if we are not going to try to benefit from it?\\n```\\n\\nJustifications are not necessary.\\n\\nReturn ONLY the JSON. I will parse the string result in JSON format.',\n",
       " 'task_name': 'Civic and Political Lean',\n",
       " 'result': '{\\n    \"civic\": \"civic\",\\n    \"political_ideology\": \"left-leaning\",\\n    \"reason_civic\": \"The post references a specific policy proposal by a politician (Bernie Sanders) and discusses its potential benefits.\",\\n    \"reason_political_ideology\": \"The post\\'s tone and language, as well as its reference to a left-leaning politician\\'s proposal, suggest a left-leaning political ideology.\"\\n}'}"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classified_results[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's hydrate the results from the classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "hydrated_classified_results: list[dict] = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error with post https://bsky.app/profile/blueheronfarm.bsky.social/post/3knmci6lfht2e at index 31: '{' was never closed (<string>, line 1)\n",
      "Error with post https://bsky.app/profile/brendelbored.bsky.social/post/3knobbmewi22h at index 59: '{' was never closed (<string>, line 1)\n",
      "Error with post https://bsky.app/profile/mangmangmang.bsky.social/post/3kno26hkn222u at index 72: name 'null' is not defined\n",
      "Error with post https://bsky.app/profile/alexanderchee.bsky.social/post/3knincv5iv225 at index 88: name 'null' is not defined\n",
      "Error with post https://bsky.app/profile/kjhealy.bsky.social/post/3knl7425rb22z at index 93: '{' was never closed (<string>, line 1)\n",
      "Error with post https://bsky.app/profile/maxkennerly.bsky.social/post/3kndtrgi6ql25 at index 95: name 'null' is not defined\n",
      "Error with post https://bsky.app/profile/jbouie.bsky.social/post/3knstcm42kk2h at index 128: '{' was never closed (<string>, line 1)\n",
      "Error with post https://bsky.app/profile/golikehellmachine.bsky.social/post/3knh3acqchc2y at index 134: name 'null' is not defined\n",
      "Error with post https://bsky.app/profile/kevinmkruse.bsky.social/post/3knonbpmxos2e at index 164: '{' was never closed (<string>, line 1)\n",
      "Error with post https://bsky.app/profile/rincewind.run/post/3knjqnssmzr2a at index 168: name 'null' is not defined\n",
      "Error with post https://bsky.app/profile/markharris.bsky.social/post/3knf7uyywym2i at index 172: name 'null' is not defined\n",
      "Error with post https://bsky.app/profile/rem.postes.club/post/3knt6owr3ft2e at index 228: '{' was never closed (<string>, line 1)\n",
      "Error with post https://bsky.app/profile/its.cassie.baby/post/3kntjyscy5n2v at index 269: '{' was never closed (<string>, line 1)\n",
      "Error with post https://bsky.app/profile/cait.bsky.social/post/3knu3yxy66u24 at index 308: name 'null' is not defined\n",
      "Error with post https://bsky.app/profile/npr.org/post/3kntix5jcnv2n at index 322: 'reason_civic'\n",
      "Error with post https://bsky.app/profile/gonebabygone.bsky.social/post/3knttvqsy3e2a at index 332: name 'null' is not defined\n",
      "Error with post https://bsky.app/profile/jbouie.bsky.social/post/3knsy3i6gwk2z at index 337: name 'null' is not defined\n",
      "Error with post https://bsky.app/profile/jbouie.bsky.social/post/3knt276ygec2j at index 341: name 'null' is not defined\n",
      "Error with post https://bsky.app/profile/ruemcclammyhand.bsky.social/post/3kntuinenm323 at index 353: name 'null' is not defined\n"
     ]
    }
   ],
   "source": [
    "for idx, post in enumerate(classified_results):\n",
    "    hydrated_res = {**post}\n",
    "    try:\n",
    "        post_dict = eval(post[\"result\"])\n",
    "        hydrated_res[\"valid_json_response\"] = True\n",
    "        hydrated_res[\"hydrated_result\"] = post_dict\n",
    "        hydrated_res[\"civic_label\"] = post_dict[\"civic\"]\n",
    "        hydrated_res[\"political_label\"] = post_dict[\"political_ideology\"]\n",
    "        hydrated_res[\"reason_civic_label\"] = post_dict[\"reason_civic\"]\n",
    "        hydrated_res[\"reason_political_label\"] = post_dict[\"reason_political_ideology\"]\n",
    "    except Exception as e:\n",
    "        # sometimes the LLM returns an invalid JSON response\n",
    "        print(f\"Error with post {post['link']} at index {idx}: {e}\")\n",
    "        hydrated_res[\"valid_json_response\"] = False\n",
    "        hydrated_res[\"hydrated_result\"] = None\n",
    "        hydrated_res[\"civic_label\"] = None\n",
    "        hydrated_res[\"political_label\"] = None\n",
    "        hydrated_res[\"reason_civic_label\"] = None\n",
    "        hydrated_res[\"reason_political_label\"] = None\n",
    "    finally:\n",
    "        hydrated_classified_results.append(hydrated_res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's export our results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "classified_posts_filename = \"classified_posts.jsonl\"\n",
    "classified_posts_fp = os.path.join(current_wd, classified_posts_filename)\n",
    "\n",
    "with open(classified_posts_fp, \"w\") as f:\n",
    "    for post in hydrated_classified_results:\n",
    "        f.write(f\"{str(post)}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "classified_posts_df: pd.DataFrame = pd.DataFrame(hydrated_classified_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's see how many valid JSONs there were"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_valid_jsons: int = sum(classified_posts_df[\"valid_json_response\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of valid JSON responses: 335\n",
      "Total number of posts: 354\n",
      "Proportion of valid JSON responses: 0.9463276836158192\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of valid JSON responses: {num_valid_jsons}\")\n",
    "print(f\"Total number of posts: {len(classified_posts_df)}\")\n",
    "print(f\"Proportion of valid JSON responses: {num_valid_jsons / len(classified_posts_df)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's compare results to the GPT labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "pilot_data_cols = [\"link\", \"civic\", \"political_ideology\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "joined_df: pd.DataFrame = pd.merge(\n",
    "    pilot_data[pilot_data_cols],\n",
    "    classified_posts_df, left_on=\"link\", right_on=\"link\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>link</th>\n",
       "      <th>civic</th>\n",
       "      <th>political_ideology</th>\n",
       "      <th>prompt</th>\n",
       "      <th>task_name</th>\n",
       "      <th>result</th>\n",
       "      <th>hydrated_result</th>\n",
       "      <th>civic_label</th>\n",
       "      <th>political_label</th>\n",
       "      <th>reason_civic_label</th>\n",
       "      <th>reason_political_label</th>\n",
       "      <th>valid_json_response</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://bsky.app/profile/jbouie.bsky.social/po...</td>\n",
       "      <td>True</td>\n",
       "      <td>left-leaning</td>\n",
       "      <td>\\n\\nPretend that you are a classifier that pre...</td>\n",
       "      <td>Civic and Political Lean</td>\n",
       "      <td>{\\n    \"civic\": \"civic\",\\n    \"political_ideol...</td>\n",
       "      <td>{'civic': 'civic', 'political_ideology': 'left...</td>\n",
       "      <td>civic</td>\n",
       "      <td>left-leaning</td>\n",
       "      <td>The post references a specific policy proposal...</td>\n",
       "      <td>The post's tone and language, as well as its r...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://bsky.app/profile/lethalityjane.bsky.so...</td>\n",
       "      <td>True</td>\n",
       "      <td>right-leaning</td>\n",
       "      <td>\\n\\nPretend that you are a classifier that pre...</td>\n",
       "      <td>Civic and Political Lean</td>\n",
       "      <td>{\\n    \"civic\": \"civic\",\\n    \"political_ideol...</td>\n",
       "      <td>{'civic': 'civic', 'political_ideology': 'righ...</td>\n",
       "      <td>civic</td>\n",
       "      <td>right-leaning</td>\n",
       "      <td>The post discusses social issues affecting tee...</td>\n",
       "      <td>The post's emphasis on individual responsibili...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://bsky.app/profile/esqueer.bsky.social/p...</td>\n",
       "      <td>True</td>\n",
       "      <td>left-leaning</td>\n",
       "      <td>\\n\\nPretend that you are a classifier that pre...</td>\n",
       "      <td>Civic and Political Lean</td>\n",
       "      <td>{\\n    \"civic\": \"civic\",\\n    \"political_ideol...</td>\n",
       "      <td>{'civic': 'civic', 'political_ideology': 'left...</td>\n",
       "      <td>civic</td>\n",
       "      <td>left-leaning</td>\n",
       "      <td>The post discusses censorship and neo-nazism, ...</td>\n",
       "      <td>The post's criticism of neo-nazism and its ass...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://bsky.app/profile/stuflemingnz.bsky.soc...</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>\\n\\nPretend that you are a classifier that pre...</td>\n",
       "      <td>Civic and Political Lean</td>\n",
       "      <td>{\\n    \"civic\": \"not civic\",\\n    \"political_i...</td>\n",
       "      <td>{'civic': 'not civic', 'political_ideology': '...</td>\n",
       "      <td>not civic</td>\n",
       "      <td>unclear</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://bsky.app/profile/sararoseg.bsky.social...</td>\n",
       "      <td>True</td>\n",
       "      <td>left-leaning</td>\n",
       "      <td>\\n\\nPretend that you are a classifier that pre...</td>\n",
       "      <td>Civic and Political Lean</td>\n",
       "      <td>{\\n    \"civic\": \"civic\",\\n    \"political_ideol...</td>\n",
       "      <td>{'civic': 'civic', 'political_ideology': 'left...</td>\n",
       "      <td>civic</td>\n",
       "      <td>left-leaning</td>\n",
       "      <td>The post discusses historical events related t...</td>\n",
       "      <td>The post presents a critical view of the Nazi ...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                link  civic  \\\n",
       "0  https://bsky.app/profile/jbouie.bsky.social/po...   True   \n",
       "1  https://bsky.app/profile/lethalityjane.bsky.so...   True   \n",
       "2  https://bsky.app/profile/esqueer.bsky.social/p...   True   \n",
       "3  https://bsky.app/profile/stuflemingnz.bsky.soc...  False   \n",
       "4  https://bsky.app/profile/sararoseg.bsky.social...   True   \n",
       "\n",
       "  political_ideology                                             prompt  \\\n",
       "0       left-leaning  \\n\\nPretend that you are a classifier that pre...   \n",
       "1      right-leaning  \\n\\nPretend that you are a classifier that pre...   \n",
       "2       left-leaning  \\n\\nPretend that you are a classifier that pre...   \n",
       "3                NaN  \\n\\nPretend that you are a classifier that pre...   \n",
       "4       left-leaning  \\n\\nPretend that you are a classifier that pre...   \n",
       "\n",
       "                  task_name  \\\n",
       "0  Civic and Political Lean   \n",
       "1  Civic and Political Lean   \n",
       "2  Civic and Political Lean   \n",
       "3  Civic and Political Lean   \n",
       "4  Civic and Political Lean   \n",
       "\n",
       "                                              result  \\\n",
       "0  {\\n    \"civic\": \"civic\",\\n    \"political_ideol...   \n",
       "1  {\\n    \"civic\": \"civic\",\\n    \"political_ideol...   \n",
       "2  {\\n    \"civic\": \"civic\",\\n    \"political_ideol...   \n",
       "3  {\\n    \"civic\": \"not civic\",\\n    \"political_i...   \n",
       "4  {\\n    \"civic\": \"civic\",\\n    \"political_ideol...   \n",
       "\n",
       "                                     hydrated_result civic_label  \\\n",
       "0  {'civic': 'civic', 'political_ideology': 'left...       civic   \n",
       "1  {'civic': 'civic', 'political_ideology': 'righ...       civic   \n",
       "2  {'civic': 'civic', 'political_ideology': 'left...       civic   \n",
       "3  {'civic': 'not civic', 'political_ideology': '...   not civic   \n",
       "4  {'civic': 'civic', 'political_ideology': 'left...       civic   \n",
       "\n",
       "  political_label                                 reason_civic_label  \\\n",
       "0    left-leaning  The post references a specific policy proposal...   \n",
       "1   right-leaning  The post discusses social issues affecting tee...   \n",
       "2    left-leaning  The post discusses censorship and neo-nazism, ...   \n",
       "3         unclear                                                      \n",
       "4    left-leaning  The post discusses historical events related t...   \n",
       "\n",
       "                              reason_political_label  valid_json_response  \n",
       "0  The post's tone and language, as well as its r...                 True  \n",
       "1  The post's emphasis on individual responsibili...                 True  \n",
       "2  The post's criticism of neo-nazism and its ass...                 True  \n",
       "3                                                                    True  \n",
       "4  The post presents a critical view of the Nazi ...                 True  "
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joined_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's only get the ones that we got valid results from "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_results_df: pd.DataFrame = joined_df[joined_df[\"valid_json_response\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, given these, let's compare the labels from GPT4 to the labels from Llama3-8b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "civic\n",
      "False    173\n",
      "True     162\n",
      "Name: count, dtype: int64\n",
      "political_ideology\n",
      "left-leaning     129\n",
      "unclear           16\n",
      "right-leaning     15\n",
      " left-leaning      1\n",
      "moderate           1\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# from GPT4\n",
    "print(filtered_results_df[\"civic\"].value_counts())\n",
    "print(filtered_results_df[\"political_ideology\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "civic_label\n",
      "civic        189\n",
      "not civic    146\n",
      "Name: count, dtype: int64\n",
      "political_label\n",
      "unclear          175\n",
      "left-leaning     123\n",
      "right-leaning     34\n",
      "moderate           3\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# from Llama3-8b\n",
    "print(filtered_results_df[\"civic_label\"].value_counts())\n",
    "print(filtered_results_df[\"political_label\"].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's fix some of the labels from the pilot data. There is a \" left-leaning\" value that should be \"left-leaning\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/9g/nhh_jmv17sd2604y43zdctzw0000gn/T/ipykernel_23716/3734042687.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_results_df[\"political_ideology\"] = filtered_results_df[\"political_ideology\"].replace(\" left-leaning\", \"left-leaning\")\n"
     ]
    }
   ],
   "source": [
    "# in the \"political_ideology\" column, there is a \" left-leaning\" value that needs\n",
    "# to be replaced with \"left-leaning\"\n",
    "filtered_results_df[\"political_ideology\"] = filtered_results_df[\"political_ideology\"].replace(\" left-leaning\", \"left-leaning\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "political_ideology\n",
      "left-leaning     130\n",
      "unclear           16\n",
      "right-leaning     15\n",
      "moderate           1\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(filtered_results_df[\"political_ideology\"].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OK, now let's compare civic-ness between both models using a confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create an cross-tab of the \"civic\" and \"civic-label\" columns. Rename the \n",
    "# \"civic\" as \"GPT-4 label\" and \"civic-label\" as \"Llama3-8b label\". Where\n",
    "# the \"GPT4-label\" is True, replace with \"civic\" (not in place, only in the crosstab)\n",
    "# and replace \"False\" with \"not civic\"\n",
    "civic_crosstab: pd.DataFrame = pd.crosstab(\n",
    "    filtered_results_df[\"civic\"],\n",
    "    filtered_results_df[\"civic_label\"].apply(lambda x: x == \"civic\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt_4_civic_results = filtered_results_df[\"civic\"]\n",
    "gpt_4_civic_results = gpt_4_civic_results.replace(True, \"civic\")\n",
    "gpt_4_civic_results = gpt_4_civic_results.replace(False, \"not civic\")\n",
    "llama_3_8b_civic_results = filtered_results_df[\"civic_label\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare gpt4 to llama results. Name each axis based on the model that it\n",
    "# came from (\"GPT-4\" or \"Llama3-8b\")\n",
    "civic_crosstab: pd.DataFrame = pd.crosstab(\n",
    "    gpt_4_civic_results, llama_3_8b_civic_results,\n",
    "    colnames=[\"Llama3-8b (columns)\"], rownames=[\"GPT-4 (rows)\"],\n",
    "    margins=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Llama3-8b (columns)</th>\n",
       "      <th>civic</th>\n",
       "      <th>not civic</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GPT-4 (rows)</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>civic</th>\n",
       "      <td>106</td>\n",
       "      <td>56</td>\n",
       "      <td>162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>not civic</th>\n",
       "      <td>83</td>\n",
       "      <td>90</td>\n",
       "      <td>173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>189</td>\n",
       "      <td>146</td>\n",
       "      <td>335</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Llama3-8b (columns)  civic  not civic  All\n",
       "GPT-4 (rows)                              \n",
       "civic                  106         56  162\n",
       "not civic               83         90  173\n",
       "All                    189        146  335"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# columns are Llama3-8b, rows are GPT-4.\n",
    "# there are a total of 189 civic posts from Llama (162 from GPT4)\n",
    "civic_crosstab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's calculate the cross-tab as a proportion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "civic_crosstab_props: pd.DataFrame = pd.crosstab(\n",
    "    gpt_4_civic_results, llama_3_8b_civic_results,\n",
    "    colnames=[\"Llama3-8b (columns)\"], rownames=[\"GPT-4 (rows)\"],\n",
    "    margins=True, normalize=\"all\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Llama3-8b</th>\n",
       "      <th>civic</th>\n",
       "      <th>not civic</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GPT-4</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>civic</th>\n",
       "      <td>0.316418</td>\n",
       "      <td>0.167164</td>\n",
       "      <td>0.483582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>not civic</th>\n",
       "      <td>0.247761</td>\n",
       "      <td>0.268657</td>\n",
       "      <td>0.516418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>0.564179</td>\n",
       "      <td>0.435821</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Llama3-8b     civic  not civic       All\n",
       "GPT-4                                   \n",
       "civic      0.316418   0.167164  0.483582\n",
       "not civic  0.247761   0.268657  0.516418\n",
       "All        0.564179   0.435821  1.000000"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "civic_crosstab_props"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's calculate precision, recall, and F1 score based on the confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = gpt_4_civic_results.tolist()\n",
    "y_pred = llama_3_8b_civic_results.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['civic', 'civic', 'civic', 'not civic', 'civic']"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_true[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "civic_metrics = precision_recall_fscore_support(\n",
    "    y_true=y_true, y_pred=y_pred, average=\"binary\", pos_label=\"civic\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "civic_precision, civic_recall, civic_fbeta_score, civic_support = civic_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.5608465608465608\tRecall: 0.654320987654321\tF-1 score: 0.603988603988604\tSupport: None\n"
     ]
    }
   ],
   "source": [
    "print(f\"Precision: {civic_precision}\\tRecall: {civic_recall}\\tF-1 score: {civic_fbeta_score}\\tSupport: {civic_support}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now do the same comparison for political ideology. For the political ideology, we only want posts that are civic. Let's take the posts that both GPT4 and Llama3-8b agreed are civic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "# both \"civic_label\" == \"civic\" and \"civic\" == True\n",
    "civic_posts: pd.DataFrame = filtered_results_df[\n",
    "    (filtered_results_df[\"civic_label\"] == \"civic\")\n",
    "    & (filtered_results_df[\"civic\"] == True)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "civic_posts = civic_posts[[\"political_ideology\", \"political_label\"]].rename(\n",
    "    columns={\"political_ideology\": \"GPT-4 political ideology\", \"political_label\": \"Llama3-8b political ideology\"}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GPT-4 political ideology</th>\n",
       "      <th>Llama3-8b political ideology</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>left-leaning</td>\n",
       "      <td>left-leaning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>right-leaning</td>\n",
       "      <td>right-leaning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>left-leaning</td>\n",
       "      <td>left-leaning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>left-leaning</td>\n",
       "      <td>left-leaning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>unclear</td>\n",
       "      <td>left-leaning</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  GPT-4 political ideology Llama3-8b political ideology\n",
       "0             left-leaning                 left-leaning\n",
       "1            right-leaning                right-leaning\n",
       "2             left-leaning                 left-leaning\n",
       "4             left-leaning                 left-leaning\n",
       "5                  unclear                 left-leaning"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "civic_posts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPT-4 political ideology\n",
      "left-leaning     83\n",
      "right-leaning    11\n",
      "unclear          11\n",
      "moderate          1\n",
      "Name: count, dtype: int64\n",
      "Llama3-8b political ideology\n",
      "left-leaning     70\n",
      "right-leaning    20\n",
      "unclear          14\n",
      "moderate          2\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(civic_posts[\"GPT-4 political ideology\"].value_counts())\n",
    "print(civic_posts[\"Llama3-8b political ideology\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "political_ideology_confusion_matrix = pd.crosstab(\n",
    "    civic_posts[\"GPT-4 political ideology\"], civic_posts[\"Llama3-8b political ideology\"],\n",
    "    rownames=[\"GPT-4 political ideology (rows)\"], colnames=[\"Llama3-8b political ideology (columns)\"],\n",
    "    margins=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Llama3-8b political ideology (columns)</th>\n",
       "      <th>left-leaning</th>\n",
       "      <th>moderate</th>\n",
       "      <th>right-leaning</th>\n",
       "      <th>unclear</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GPT-4 political ideology (rows)</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>left-leaning</th>\n",
       "      <td>62</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>9</td>\n",
       "      <td>83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>moderate</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>right-leaning</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unclear</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>70</td>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>14</td>\n",
       "      <td>106</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Llama3-8b political ideology (columns)  left-leaning  moderate  right-leaning  \\\n",
       "GPT-4 political ideology (rows)                                                 \n",
       "left-leaning                                      62         0             12   \n",
       "moderate                                           0         0              1   \n",
       "right-leaning                                      2         2              5   \n",
       "unclear                                            6         0              2   \n",
       "All                                               70         2             20   \n",
       "\n",
       "Llama3-8b political ideology (columns)  unclear  All  \n",
       "GPT-4 political ideology (rows)                       \n",
       "left-leaning                                  9   83  \n",
       "moderate                                      0    1  \n",
       "right-leaning                                 2   11  \n",
       "unclear                                       3   11  \n",
       "All                                          14  106  "
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "political_ideology_confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "political_ideology_confusion_matrix_props = pd.crosstab(\n",
    "    civic_posts[\"GPT-4 political ideology\"], civic_posts[\"Llama3-8b political ideology\"],\n",
    "    rownames=[\"GPT-4 political ideology (rows)\"], colnames=[\"Llama3-8b political ideology (columns)\"],\n",
    "    margins=True, normalize=\"all\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Llama3-8b political ideology (columns)</th>\n",
       "      <th>left-leaning</th>\n",
       "      <th>moderate</th>\n",
       "      <th>right-leaning</th>\n",
       "      <th>unclear</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GPT-4 political ideology (rows)</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>left-leaning</th>\n",
       "      <td>0.584906</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.113208</td>\n",
       "      <td>0.084906</td>\n",
       "      <td>0.783019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>moderate</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.009434</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.009434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>right-leaning</th>\n",
       "      <td>0.018868</td>\n",
       "      <td>0.018868</td>\n",
       "      <td>0.047170</td>\n",
       "      <td>0.018868</td>\n",
       "      <td>0.103774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unclear</th>\n",
       "      <td>0.056604</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.018868</td>\n",
       "      <td>0.028302</td>\n",
       "      <td>0.103774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>0.660377</td>\n",
       "      <td>0.018868</td>\n",
       "      <td>0.188679</td>\n",
       "      <td>0.132075</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Llama3-8b political ideology (columns)  left-leaning  moderate  right-leaning  \\\n",
       "GPT-4 political ideology (rows)                                                 \n",
       "left-leaning                                0.584906  0.000000       0.113208   \n",
       "moderate                                    0.000000  0.000000       0.009434   \n",
       "right-leaning                               0.018868  0.018868       0.047170   \n",
       "unclear                                     0.056604  0.000000       0.018868   \n",
       "All                                         0.660377  0.018868       0.188679   \n",
       "\n",
       "Llama3-8b political ideology (columns)   unclear       All  \n",
       "GPT-4 political ideology (rows)                             \n",
       "left-leaning                            0.084906  0.783019  \n",
       "moderate                                0.000000  0.009434  \n",
       "right-leaning                           0.018868  0.103774  \n",
       "unclear                                 0.028302  0.103774  \n",
       "All                                     0.132075  1.000000  "
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "political_ideology_confusion_matrix_props"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "political_ideology_metrics = precision_recall_fscore_support(\n",
    "    y_true=civic_posts[\"GPT-4 political ideology\"].tolist(),\n",
    "    y_pred=civic_posts[\"Llama3-8b political ideology\"].tolist(),\n",
    "    average=\"weighted\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "political_ideology_recall, political_ideology_precision, political_ideology_fbeta_score, political_ideology_support = political_ideology_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.660377358490566\tRecall: 0.7417115902964959\tF-1 score: 0.6929845372922957\tSupport: None\n"
     ]
    }
   ],
   "source": [
    "print(f\"Precision: {political_ideology_precision}\\tRecall: {political_ideology_recall}\\tF-1 score: {political_ideology_fbeta_score}\\tSupport: {political_ideology_support}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bluesky-research",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
