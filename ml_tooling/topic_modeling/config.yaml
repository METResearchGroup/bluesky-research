embedding_model:
  name: "all-MiniLM-L6-v2"
  device: "auto"
  batch_size: 32

bertopic:
  top_n_words: 20
  min_topic_size: 15
  nr_topics: "auto"
  calculate_probabilities: true
  verbose: true
  # UMAP configuration for better performance and clustering
  umap_model:
    n_neighbors: 15
    n_components: 10  # Increased from 5 to 10 for better clustering potential
    min_dist: 0.0
    metric: "cosine"
    n_jobs: 1  # Disable UMAP multiprocessing
    low_memory: true  # Reduce memory usage
  # HDBSCAN configuration optimized for large datasets
  hdbscan_model:
    min_cluster_size: 10  # Reduced from 15 to 10 for more clusters
    min_samples: 3  # Reduced from 5 to 3 for less restrictive clustering
    metric: "euclidean"
    cluster_selection_method: "eom"
    core_dist_n_jobs: 1  # Disable HDBSCAN multiprocessing
    # Additional parameters for better clustering
    cluster_selection_epsilon: 0.1  # Allow more flexible cluster selection
    allow_single_cluster: True  # Allow single cluster if data suggests it

quality_thresholds:
  c_v_min: 0.4
  c_npmi_min: 0.1

gpu_optimization:
  enable: true
  max_batch_size: 128
  memory_threshold: 0.8

# Performance and logging configuration
performance:
  # Enable progress logging during clustering
  enable_progress_logging: true
  # Log progress every N documents during clustering
  progress_log_interval: 10000
  # Enable timing breakdown for each pipeline stage
  enable_timing_breakdown: true

random_seed: 42

# Text preprocessing configuration
text_preprocessing:
  enable: true
  remove_stopwords: true
  language: "english"
  min_word_length: 2
  remove_urls: true
  remove_emojis: true
  custom_stopwords:
    # Social media specific stopwords
    - "rt"
    - "via"
    - "amp"
    - "u"
    - "ur"
    - "im"
    - "ill"
    - "ive"
    - "id"
    - "dont"
    - "cant"
    - "wont"
    - "wouldnt"
    - "couldnt"
    - "shouldnt"
    - "thats"
    - "theres"
    - "theyre"
    - "youre"
    - "were"
    - "shes"
    - "hes"
    - "its"
